{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('cnn/stories/*.story')\n",
    "# print(len(files))\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"beatles/i'll-cry-instead.txt\",\n",
       " 'beatles/hey-jude.txt',\n",
       " \"beatles/nothin'-shakin'.txt\",\n",
       " 'beatles/i-will.txt',\n",
       " 'beatles/child-of-nature.txt',\n",
       " 'beatles/helter-skelter.txt',\n",
       " 'beatles/i-am-the-walrus.txt',\n",
       " 'beatles/glad-all-over.txt',\n",
       " 'beatles/johnny-b.-goode.txt',\n",
       " 'beatles/christmas-time.txt',\n",
       " 'beatles/i-call-your-name.txt',\n",
       " 'beatles/no-reply.txt',\n",
       " 'beatles/hello,-little-girl.txt',\n",
       " 'beatles/good-day-sunshine.txt',\n",
       " 'beatles/clarabella.txt',\n",
       " 'beatles/act-naturally.txt',\n",
       " 'beatles/dear-wack!.txt',\n",
       " 'beatles/chains.txt',\n",
       " 'beatles/blackbird.txt',\n",
       " 'beatles/keep-your-hands-off-my-baby.txt',\n",
       " 'beatles/get-back.txt',\n",
       " 'beatles/happiness-is-a-warm-gun.txt',\n",
       " 'beatles/if-i-needed-someone-to-love.txt',\n",
       " 'beatles/crinsk-dee-night.txt',\n",
       " 'beatles/commonwealth.txt',\n",
       " 'beatles/norwegian-wood.txt',\n",
       " \"beatles/ain't-she-sweet.txt\",\n",
       " 'beatles/lucille.txt',\n",
       " 'beatles/nowhere-man.txt',\n",
       " 'beatles/give-peace-a-chance.txt',\n",
       " 'beatles/from-me-to-you.txt',\n",
       " 'beatles/help!.txt',\n",
       " \"beatles/i'll-be-on-my-way.txt\",\n",
       " \"beatles/i'll-be-back.txt\",\n",
       " \"beatles/don't-bother-me.txt\",\n",
       " 'beatles/kansa-city.txt',\n",
       " 'beatles/michelle.txt',\n",
       " 'beatles/day-tripper.txt',\n",
       " \"beatles/it's-all-too-much.txt\",\n",
       " 'beatles/a-taste-of-honey.txt',\n",
       " \"beatles/all-i've-got-to-do.txt\",\n",
       " 'beatles/jingle-bells.txt',\n",
       " 'beatles/have-a-banana!.txt',\n",
       " 'beatles/across-the-universe.txt',\n",
       " 'beatles/money.txt',\n",
       " 'beatles/cry-baby-cry.txt',\n",
       " 'beatles/come-and-get-it.txt',\n",
       " 'beatles/blue-suede-shoes.txt',\n",
       " 'beatles/love-you-to.txt',\n",
       " 'beatles/honey-pie.txt',\n",
       " 'beatles/love-these-goon-shows!.txt',\n",
       " \"beatles/honey,-don't.txt\",\n",
       " 'beatles/and-i-love-her.txt',\n",
       " 'beatles/a-day-in-the-life.txt',\n",
       " \"beatles/i'm-looking-through-you.txt\",\n",
       " 'beatles/my-bonnie.txt',\n",
       " 'beatles/do-you-want-to-know-a-secret.txt',\n",
       " 'beatles/dear-prudence.txt',\n",
       " 'beatles/i-got-a-woman.txt',\n",
       " 'beatles/come-together.txt',\n",
       " 'beatles/mean-mr.-mustard.txt',\n",
       " 'beatles/old-brown-shoe.txt',\n",
       " 'beatles/komm,-gib-mir-deine-hand.txt',\n",
       " \"beatles/i'm-happy-just-to-dance-with-you.txt\",\n",
       " 'beatles/any-time-at-all.txt',\n",
       " 'beatles/bad-to-me.txt',\n",
       " 'beatles/hallelujah,-i-love-her-so.txt',\n",
       " 'beatles/hold-me-tight.txt',\n",
       " 'beatles/i-saw-her-standing.txt',\n",
       " \"beatles/i've-got-a-feeling.txt\",\n",
       " 'beatles/lend-me-your-comb.txt',\n",
       " \"beatles/a-hard-day's-night.txt\",\n",
       " 'beatles/and-your-bird-can-sing.txt',\n",
       " 'beatles/being-for-the-benefit-of-mr.-kite.txt',\n",
       " 'beatles/i-me-mine.txt',\n",
       " 'beatles/follow-the-sun.txt',\n",
       " \"beatles/don't-let-me-down.txt\",\n",
       " 'beatles/all-together-now.txt',\n",
       " 'beatles/girl.txt',\n",
       " \"beatles/i've-just-seen-a-face.txt\",\n",
       " 'beatles/glass-onion.txt',\n",
       " 'beatles/misery.txt',\n",
       " 'beatles/how-do-you-do-it.txt',\n",
       " 'beatles/in-my-life.txt',\n",
       " 'beatles/all-you-need-is-love.txt',\n",
       " 'beatles/imagine.txt',\n",
       " 'beatles/dizzy-miss-lizzy.txt',\n",
       " 'beatles/got-to-get-it-into-my-life.txt',\n",
       " 'beatles/mr.-moonlight.txt',\n",
       " 'beatles/carol.txt',\n",
       " 'beatles/every-little-thing.txt',\n",
       " 'beatles/all-things-must-pass.txt',\n",
       " 'beatles/love-of-the-loved.txt',\n",
       " 'beatles/for-no-one.txt',\n",
       " 'beatles/i-wanna-be-your-man.txt',\n",
       " 'beatles/like-dreamers-do.txt',\n",
       " 'beatles/all-my-loving.txt',\n",
       " 'beatles/i-want-to-tell-you.txt',\n",
       " 'beatles/ask-me-why.txt',\n",
       " 'beatles/lovely-rita.txt',\n",
       " 'beatles/anna,-go-to-him.txt',\n",
       " 'beatles/devil-in-her-heart.txt',\n",
       " 'beatles/in-spite-of-all-the-danger.txt',\n",
       " \"beatles/i'm-down.txt\",\n",
       " 'beatles/oh!-darling.txt',\n",
       " 'beatles/if-i-needed-someone.txt',\n",
       " 'beatles/cold-turkey.txt',\n",
       " 'beatles/a-little-rhyme.txt',\n",
       " 'beatles/dr.-robert.txt',\n",
       " \"beatles/it's-only-love.txt\",\n",
       " 'beatles/magical-mystery-tour.txt',\n",
       " 'beatles/leave-my-kitten-alone.txt',\n",
       " \"beatles/i-don't-want-to-spoil-the-party.txt\",\n",
       " 'beatles/good-morning,-good-morning.txt',\n",
       " 'beatles/long-tall-sally.txt',\n",
       " 'beatles/ob-la-di,-ob-la-da.txt',\n",
       " 'beatles/not-guilty.txt',\n",
       " 'beatles/little-child.txt',\n",
       " 'beatles/i-want-to-hold-your-hand.txt',\n",
       " \"beatles/i'm-only-sleeping.txt\",\n",
       " 'beatles/let-it-be.txt',\n",
       " 'beatles/another-girl.txt',\n",
       " 'beatles/boys.txt',\n",
       " \"beatles/don't-pass-me-by.txt\",\n",
       " \"beatles/baby,-it's-you.txt\",\n",
       " \"beatles/octopus's-garden.txt\",\n",
       " \"beatles/i'm-so-tired.txt\",\n",
       " 'beatles/memphis,-tenessee.txt',\n",
       " 'beatles/los-paranoias.txt',\n",
       " 'beatles/blue-jay-way.txt',\n",
       " 'beatles/back-in-the-ussr.txt',\n",
       " \"beatles/i'm-a-loser.txt\",\n",
       " 'beatles/here-comes-the-sun.txt',\n",
       " 'beatles/junk.txt',\n",
       " 'beatles/lucy-in-the-sky-with-diamonds.txt',\n",
       " 'beatles/if-i-fell.txt',\n",
       " \"beatles/everybody's-got-something-to-hide-except-me-and-my-monkey.txt\",\n",
       " 'beatles/eleanor-rigby.txt',\n",
       " 'beatles/i-feel-fine.txt',\n",
       " 'beatles/julia.txt',\n",
       " 'beatles/hello,-goodbye.txt',\n",
       " \"beatles/don't-ever-change.txt\",\n",
       " 'beatles/just-a-rumour.txt',\n",
       " \"beatles/i'll-get-you.txt\",\n",
       " 'beatles/fixing-a-hole.txt',\n",
       " 'beatles/golden-slumbers.txt',\n",
       " 'beatles/good-night.txt',\n",
       " \"beatles/everybody's-trying-to-be-my-baby.txt\",\n",
       " \"beatles/i'm-gonna-sit-right-down-and-cry.txt\",\n",
       " 'beatles/birthday.txt',\n",
       " 'beatles/eight-days-a-week.txt',\n",
       " 'beatles/besame-mucho.txt',\n",
       " 'beatles/bad-boy.txt',\n",
       " 'beatles/martha,-my-dear.txt',\n",
       " 'beatles/crying,-waiting,-hoping.txt',\n",
       " 'beatles/i-want-you.txt',\n",
       " 'beatles/getting-better.txt',\n",
       " 'beatles/mrs.-robinson.txt',\n",
       " 'beatles/love-me-do.txt',\n",
       " 'beatles/matchbox.txt',\n",
       " 'beatles/lady-madonna.txt',\n",
       " \"beatles/baby's-in-black.txt\",\n",
       " 'beatles/i-need-you.txt',\n",
       " \"beatles/if-you've-got-trouble.txt\",\n",
       " 'beatles/if-you-love-me-baby.txt',\n",
       " \"beatles/can't-buy-me-love.txt\",\n",
       " 'beatles/i-got-to-find-my-baby.txt',\n",
       " 'beatles/carry-that-weight.txt',\n",
       " 'beatles/a-shot-of-rhythm-and-blues.txt',\n",
       " \"beatles/it-won't-be-long.txt\",\n",
       " 'beatles/hey-bulldog.txt',\n",
       " 'beatles/free-as-a-bird.txt',\n",
       " \"beatles/baby,-you're-a-rich-man.txt\",\n",
       " 'beatles/drive-my-car.txt',\n",
       " \"beatles/nobody's-child.txt\",\n",
       " 'beatles/not-a-second-time.txt',\n",
       " 'beatles/dig-a-pony.txt',\n",
       " 'beatles/for-you-blue.txt']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('beatles/*.txt')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method for generating text from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # replace all occurences of multiple newlines and replace them\n",
    "    # with a single newline padded with spaces so it is treated as a\n",
    "    # token\n",
    "    text = ' \\n '.join(t for t in text.split('\\n') if t)\n",
    "    text = 'songbegin %s songend' % text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generator(files, splitter=None, preprocessor=None):\n",
    "    # splitter is responsible for breaking up text into smaller sequences\n",
    "    # i.e. perhaps by splitting on \\n\n",
    "    for f in files:\n",
    "        text = open(f).read()\n",
    "        if preprocessor is not None:\n",
    "            text = preprocessor(text)\n",
    "        # remove highlights\n",
    "        text = text.split('@highlight')[0]\n",
    "        if splitter is None:\n",
    "            text = [text]\n",
    "        else:\n",
    "            text = splitter(text)\n",
    "        for t in text:\n",
    "            if not t or len(t) < 10:\n",
    "                continue\n",
    "            yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"songbegin I've got every reason on earth to be mad \\n 'Cause I just lost the only girl I had \\n If I could get my way \\n I'd get myself locked up today \\n But I can't, so I'll cry instead \\n I've got a chip on my shoulder that's bigger that my feet \\n I can't talk to people that I meet \\n If I could see you now \\n I'd try to make you sad somehow \\n But I can't, so I'll cry instead \\n Don't want to cry when there's people there \\n I get shy when they start to stare \\n I'm gonna hide myself away \\n But I'll come back again someday \\n And when you do you'd better hide all the girls \\n I'm gonna break their hearts all round the world \\n Yes, I'm gonna break them in two \\n And show you what your lovin' man can do \\n Until then I'll cry instead songend\""
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(text_generator(files, preprocessor=preprocessor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = text_generator(files, preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=1000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t',  # no newline\n",
    "    oov_token='<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 4.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550,\n",
       " {'\\n\\n': 53,\n",
       "  '\\n\\nand': 329,\n",
       "  '\\n\\nchristmas': 168,\n",
       "  '\\n\\ndo': 427,\n",
       "  '\\n\\nfor': 312,\n",
       "  '\\n\\ngeorge': 374,\n",
       "  '\\n\\ngo': 501,\n",
       "  '\\n\\nhe': 462,\n",
       "  '\\n\\nhelter': 429,\n",
       "  '\\n\\nlook': 129,\n",
       "  '\\n\\nlove': 321,\n",
       "  \"\\n\\nshe's\": 179,\n",
       "  '\\n\\nthis': 113,\n",
       "  '\\n\\nthough': 193,\n",
       "  '\\n\\ntried': 535,\n",
       "  '\\n\\nwe': 404,\n",
       "  '\\n\\nwell': 218,\n",
       "  '\\n\\nwhen': 434,\n",
       "  '\\n\\nwill': 430,\n",
       "  '\\naah': 131,\n",
       "  '\\nand': 393,\n",
       "  '\\ngo': 38,\n",
       "  '\\ni': 116,\n",
       "  \"\\ni'm\": 424,\n",
       "  '\\nlook': 431,\n",
       "  '\\nmy': 399,\n",
       "  '\\noh': 189,\n",
       "  '\\none': 198,\n",
       "  '\\nplease': 192,\n",
       "  '\\nspent': 183,\n",
       "  '\\nthe': 409,\n",
       "  '\\nthen': 185,\n",
       "  \"\\nthere's\": 42,\n",
       "  '\\ntill': 203,\n",
       "  '\\ntried': 416,\n",
       "  '\\nwhy': 418,\n",
       "  '\\nyes': 219,\n",
       "  \"'cause\": 432,\n",
       "  '<unk>': 550,\n",
       "  'a': 7,\n",
       "  'about': 176,\n",
       "  'above': 428,\n",
       "  'act': 182,\n",
       "  'afraid\\nyou': 230,\n",
       "  'again': 102,\n",
       "  \"again\\n\\nain't\": 109,\n",
       "  'again\\nchristmas': 37,\n",
       "  'again\\no': 165,\n",
       "  \"ain't\": 87,\n",
       "  'air\\nsing': 333,\n",
       "  'all': 19,\n",
       "  'always': 319,\n",
       "  'an': 523,\n",
       "  'and': 11,\n",
       "  'answer\\nyou': 124,\n",
       "  'any': 351,\n",
       "  'anytime': 235,\n",
       "  'apart': 328,\n",
       "  'are': 411,\n",
       "  'around\\nto': 492,\n",
       "  'at': 81,\n",
       "  'away': 210,\n",
       "  'away\\nbut': 288,\n",
       "  'b': 67,\n",
       "  'baby': 55,\n",
       "  \"baby\\n'cause\": 510,\n",
       "  'baby\\ni': 397,\n",
       "  \"baby\\ni'm\": 358,\n",
       "  'back': 78,\n",
       "  'background': 363,\n",
       "  'bad\\ntake': 132,\n",
       "  'band\\nmany': 490,\n",
       "  'be': 22,\n",
       "  'be\\nsuch': 419,\n",
       "  'beating': 345,\n",
       "  'beatles': 371,\n",
       "  'been': 110,\n",
       "  'beg': 422,\n",
       "  'began': 156,\n",
       "  'begging': 425,\n",
       "  'begin': 138,\n",
       "  \"begin\\nyou're\": 249,\n",
       "  'behalf': 370,\n",
       "  'bell\\n\\ngo': 461,\n",
       "  'bended': 188,\n",
       "  'beneath': 467,\n",
       "  'better': 51,\n",
       "  'better\\n\\nand': 234,\n",
       "  'better\\n\\nhey': 229,\n",
       "  'better\\n\\nso': 248,\n",
       "  'better\\nremember': 133,\n",
       "  'big': 488,\n",
       "  'bigger': 275,\n",
       "  'blisters': 437,\n",
       "  'blow\\nand': 201,\n",
       "  'bonnie\\ngive': 223,\n",
       "  'book': 456,\n",
       "  'bottom': 84,\n",
       "  'boy': 482,\n",
       "  'boy\\nnamed': 450,\n",
       "  'break': 79,\n",
       "  'but': 57,\n",
       "  'by\\nused': 478,\n",
       "  'cabin\\nmade': 445,\n",
       "  'call': 512,\n",
       "  'can': 59,\n",
       "  \"can't\": 75,\n",
       "  'carry': 139,\n",
       "  'catch': 152,\n",
       "  'cats': 410,\n",
       "  'cheek': 539,\n",
       "  'cheek\\nmy': 540,\n",
       "  'chip': 272,\n",
       "  'christmas': 82,\n",
       "  'clay': 446,\n",
       "  'colder\\nnah': 242,\n",
       "  'come': 101,\n",
       "  'comes': 433,\n",
       "  'coming': 85,\n",
       "  'coming\\nfrom': 491,\n",
       "  'continues': 361,\n",
       "  'control\\ni': 158,\n",
       "  'cooking': 537,\n",
       "  'cool': 186,\n",
       "  'cool\\nby': 240,\n",
       "  'could': 97,\n",
       "  'country': 130,\n",
       "  'cry': 77,\n",
       "  'cry\\noh': 108,\n",
       "  'dancer': 127,\n",
       "  'dang': 68,\n",
       "  'day': 199,\n",
       "  'day\\nit': 394,\n",
       "  'day\\nyour': 497,\n",
       "  'deep': 439,\n",
       "  \"didn't\": 47,\n",
       "  'do': 103,\n",
       "  'do\\nand': 513,\n",
       "  'do\\nthe': 254,\n",
       "  'do\\nuntil': 300,\n",
       "  'do\\nwell': 227,\n",
       "  'doggone': 420,\n",
       "  \"don't\": 28,\n",
       "  'doubt': 502,\n",
       "  'down': 66,\n",
       "  'down\\nmaybe': 495,\n",
       "  'down\\nyou': 244,\n",
       "  'dreaming': 343,\n",
       "  'drivers': 475,\n",
       "  'earth': 263,\n",
       "  'ease': 206,\n",
       "  'easy': 336,\n",
       "  'electric': 524,\n",
       "  'endear': 340,\n",
       "  'ever': 151,\n",
       "  'evergreens\\nthere': 443,\n",
       "  'every': 146,\n",
       "  'everything': 367,\n",
       "  'everywhere': 380,\n",
       "  'eyes\\nthought': 353,\n",
       "  'fades': 362,\n",
       "  'fast': 86,\n",
       "  'fast\\ni': 346,\n",
       "  'feel': 45,\n",
       "  'feeling': 347,\n",
       "  'feet\\ni': 276,\n",
       "  'fill': 332,\n",
       "  'find': 154,\n",
       "  'fingers': 438,\n",
       "  'fool': 95,\n",
       "  'for': 50,\n",
       "  'forever': 322,\n",
       "  'forever\\nlove': 323,\n",
       "  'found': 245,\n",
       "  'from': 506,\n",
       "  'gang\\nand': 406,\n",
       "  'get': 30,\n",
       "  \"gilly\\nit's\": 69,\n",
       "  'girl': 267,\n",
       "  \"girls\\ni'm\": 291,\n",
       "  'give': 118,\n",
       "  'glad': 32,\n",
       "  'go': 5,\n",
       "  'goes': 494,\n",
       "  'gone': 516,\n",
       "  'gonna': 100,\n",
       "  'good': 373,\n",
       "  'good\\nwhen': 511,\n",
       "  'goode': 90,\n",
       "  'goode\\nhe': 451,\n",
       "  'goosepimples': 509,\n",
       "  'got': 60,\n",
       "  'got\\nbut': 530,\n",
       "  'grab': 415,\n",
       "  'guitar\\nin': 464,\n",
       "  'guitar\\njust': 459,\n",
       "  'gunny': 465,\n",
       "  'guy\\n\\n': 359,\n",
       "  'guy\\ni': 159,\n",
       "  'guy\\nlook': 357,\n",
       "  'guy\\nwatch': 355,\n",
       "  'had\\nif': 268,\n",
       "  'happy\\nand': 518,\n",
       "  'happy\\nchristmas': 372,\n",
       "  'hard': 389,\n",
       "  'hard\\nto': 196,\n",
       "  'harrison': 375,\n",
       "  'have': 144,\n",
       "  'he': 458,\n",
       "  'hear': 155,\n",
       "  'heart': 105,\n",
       "  'heart\\nand': 208,\n",
       "  'heart\\nlove': 325,\n",
       "  'heart\\nthen': 135,\n",
       "  'hearts': 293,\n",
       "  'heels': 413,\n",
       "  'helter': 89,\n",
       "  'her': 29,\n",
       "  'her\\nremember': 247,\n",
       "  'her\\nthe': 232,\n",
       "  'here': 16,\n",
       "  'hey': 10,\n",
       "  'hide': 149,\n",
       "  'hide\\ni': 354,\n",
       "  'high\\ni': 543,\n",
       "  'him\\nsomeday': 485,\n",
       "  'his': 73,\n",
       "  'honey': 222,\n",
       "  'hot': 91,\n",
       "  'how': 304,\n",
       "  'hurt': 54,\n",
       "  'i': 6,\n",
       "  \"i'd\": 114,\n",
       "  \"i'll\": 76,\n",
       "  \"i'm\": 23,\n",
       "  \"i've\": 74,\n",
       "  'if': 313,\n",
       "  'in': 49,\n",
       "  'insecure\\nyou': 348,\n",
       "  'inside\\ni': 161,\n",
       "  'inside\\nwhen': 538,\n",
       "  'instead\\n\\n': 302,\n",
       "  \"instead\\n\\ndon't\": 282,\n",
       "  \"instead\\n\\ni've\": 271,\n",
       "  'into': 134,\n",
       "  'is': 9,\n",
       "  'is\\n\\n': 436,\n",
       "  'it': 17,\n",
       "  'it\\nbetter': 259,\n",
       "  'it\\nthis': 503,\n",
       "  \"it's\": 141,\n",
       "  'jealous': 64,\n",
       "  'joes': 408,\n",
       "  'john': 170,\n",
       "  'johnny': 15,\n",
       "  'jude': 44,\n",
       "  'jude\\n\\n': 261,\n",
       "  'jude\\nnah': 18,\n",
       "  'just': 34,\n",
       "  'keep': 194,\n",
       "  'keys': 211,\n",
       "  'kiss': 505,\n",
       "  'kisses\\non': 187,\n",
       "  'knees': 117,\n",
       "  'know': 46,\n",
       "  'knows': 303,\n",
       "  'last': 330,\n",
       "  'leader\\nof': 487,\n",
       "  'learned\\nto': 452,\n",
       "  'leaves': 27,\n",
       "  'lennon': 171,\n",
       "  'let': 33,\n",
       "  'lets': 396,\n",
       "  'lifetime\\nif': 311,\n",
       "  'light\\nsaying': 499,\n",
       "  'like': 41,\n",
       "  'listeners': 379,\n",
       "  'listeners\\n\\n': 386,\n",
       "  'little': 143,\n",
       "  'lives': 448,\n",
       "  'locked': 98,\n",
       "  'lonely': 310,\n",
       "  'long': 305,\n",
       "  'looking\\nto': 529,\n",
       "  'lose': 157,\n",
       "  'lost': 265,\n",
       "  'loud': 334,\n",
       "  'louisianna\\nclose': 440,\n",
       "  'love': 63,\n",
       "  'love\\nit': 527,\n",
       "  'love\\none': 504,\n",
       "  'loved': 306,\n",
       "  'lover': 126,\n",
       "  \"lovin'\": 298,\n",
       "  'loving': 191,\n",
       "  'low\\nfever': 542,\n",
       "  \"mad\\n'cause\": 264,\n",
       "  'made': 71,\n",
       "  'made\\npeople': 476,\n",
       "  'make': 20,\n",
       "  'makes': 181,\n",
       "  'making': 241,\n",
       "  'mama': 484,\n",
       "  'man': 299,\n",
       "  'man\\nand': 486,\n",
       "  'mattered\\ni': 318,\n",
       "  'may': 125,\n",
       "  'mccartney': 366,\n",
       "  'me': 8,\n",
       "  'me\\nlike': 522,\n",
       "  'me\\nsome': 190,\n",
       "  \"me\\nthere'd\": 401,\n",
       "  'me\\nyou': 341,\n",
       "  'mean': 106,\n",
       "  'meet': 405,\n",
       "  'meet\\nif': 278,\n",
       "  'mercy': 514,\n",
       "  'merry': 384,\n",
       "  'might': 349,\n",
       "  'miles': 216,\n",
       "  'mine': 197,\n",
       "  'minute': 233,\n",
       "  'money': 184,\n",
       "  'more': 225,\n",
       "  'more\\ni': 352,\n",
       "  'movement': 255,\n",
       "  'much': 528,\n",
       "  'music': 360,\n",
       "  'music\\ntill': 493,\n",
       "  'must': 178,\n",
       "  'my': 13,\n",
       "  'my\\nthat': 481,\n",
       "  'myself': 147,\n",
       "  'nah': 1,\n",
       "  'nah\\n\\nhey': 243,\n",
       "  'name': 498,\n",
       "  'name\\nbut': 316,\n",
       "  'near': 337,\n",
       "  'need': 256,\n",
       "  'never': 153,\n",
       "  'new': 115,\n",
       "  'no': 88,\n",
       "  'not': 350,\n",
       "  'nothing': 25,\n",
       "  'now': 246,\n",
       "  \"now\\ni'd\": 279,\n",
       "  'of': 48,\n",
       "  'oh': 480,\n",
       "  'oh\\n\\nnah': 260,\n",
       "  'old': 489,\n",
       "  'on': 12,\n",
       "  'one': 224,\n",
       "  'only': 266,\n",
       "  'opportunity': 377,\n",
       "  'or': 454,\n",
       "  'orleans\\nway': 441,\n",
       "  'out': 39,\n",
       "  'out\\nhelter': 217,\n",
       "  \"out\\ni'm\": 356,\n",
       "  'out\\nwhat': 392,\n",
       "  'over': 549,\n",
       "  'over\\n\\nyeah': 508,\n",
       "  'over\\n\\nyour': 519,\n",
       "  'over\\nhot': 547,\n",
       "  'over\\noo': 221,\n",
       "  'over\\nooo': 228,\n",
       "  'over\\nwell': 548,\n",
       "  'over\\nyeah': 534,\n",
       "  'pain': 236,\n",
       "  'pain\\ni': 164,\n",
       "  'pappie': 400,\n",
       "  'passing': 477,\n",
       "  'past\\nand': 344,\n",
       "  'pastiche': 387,\n",
       "  'paul': 365,\n",
       "  'people': 99,\n",
       "  'perform': 252,\n",
       "  'play': 220,\n",
       "  'play\\n\\ngo': 483,\n",
       "  'playing\\nin': 472,\n",
       "  'plays': 96,\n",
       "  'please': 83,\n",
       "  'point': 388,\n",
       "  'puppy\\nand': 517,\n",
       "  'puts': 205,\n",
       "  'railroad': 469,\n",
       "  'read': 453,\n",
       "  'really': 317,\n",
       "  'really\\nhappy': 385,\n",
       "  'reason': 262,\n",
       "  \"refrain\\ndon't\": 237,\n",
       "  'rhythm\\nthat': 474,\n",
       "  'ride\\ntill': 215,\n",
       "  'ringing': 460,\n",
       "  'ringo': 381,\n",
       "  'rock': 515,\n",
       "  'rocking': 407,\n",
       "  'round': 80,\n",
       "  'sack\\nsit': 466,\n",
       "  'sad': 92,\n",
       "  'same': 320,\n",
       "  'saw': 314,\n",
       "  'say': 383,\n",
       "  'say\\nmy': 479,\n",
       "  'saying': 369,\n",
       "  'see': 62,\n",
       "  'sewed': 521,\n",
       "  'shade\\ndrumming': 473,\n",
       "  'shaking\\nbut': 26,\n",
       "  'she': 56,\n",
       "  'shine': 202,\n",
       "  'shivering': 160,\n",
       "  'shoulder': 273,\n",
       "  'shoulder\\nnah': 257,\n",
       "  'shoulders\\nfor': 239,\n",
       "  'show': 297,\n",
       "  'shows': 531,\n",
       "  'shows\\ncome': 533,\n",
       "  'shy': 285,\n",
       "  'silly\\nbut': 70,\n",
       "  'since': 111,\n",
       "  'sitting': 471,\n",
       "  'skelter': 58,\n",
       "  'skelter\\nhelter': 128,\n",
       "  \"skelter\\nshe's\": 435,\n",
       "  'skin\\nthen': 137,\n",
       "  'slide\\nwhere': 213,\n",
       "  'so': 61,\n",
       "  'some': 496,\n",
       "  'someday\\n\\nand': 289,\n",
       "  'somehow\\nbut': 281,\n",
       "  'someone': 251,\n",
       "  'something\\non': 412,\n",
       "  'song': 93,\n",
       "  'sorry': 107,\n",
       "  \"speak\\ni'm\": 544,\n",
       "  'speaking': 376,\n",
       "  'spells': 167,\n",
       "  'spoken': 364,\n",
       "  'squeeze': 417,\n",
       "  'stand': 444,\n",
       "  \"stare\\ni'm\": 287,\n",
       "  'starr': 382,\n",
       "  'start': 94,\n",
       "  'still\\nwill': 308,\n",
       "  'stop': 122,\n",
       "  'sun': 120,\n",
       "  'sure': 395,\n",
       "  'swallowing': 163,\n",
       "  't': 166,\n",
       "  'take': 174,\n",
       "  'talk': 277,\n",
       "  'tease': 421,\n",
       "  'tell': 43,\n",
       "  'temperature': 541,\n",
       "  'that': 31,\n",
       "  \"that's\": 274,\n",
       "  'the': 2,\n",
       "  'their': 292,\n",
       "  'them': 295,\n",
       "  'then': 301,\n",
       "  'there\\ni': 284,\n",
       "  \"there's\": 283,\n",
       "  'these': 403,\n",
       "  'they': 286,\n",
       "  'things': 339,\n",
       "  'this': 175,\n",
       "  'thought': 526,\n",
       "  'threw': 209,\n",
       "  'time': 14,\n",
       "  'time\\nevery': 226,\n",
       "  'time\\nshe': 204,\n",
       "  'times': 402,\n",
       "  'to': 3,\n",
       "  'today\\nbut': 270,\n",
       "  'toes': 414,\n",
       "  'together\\nlove': 327,\n",
       "  'told': 177,\n",
       "  'tonight': 500,\n",
       "  'too': 545,\n",
       "  'top': 212,\n",
       "  'touch': 520,\n",
       "  'track\\noh': 470,\n",
       "  'trees': 65,\n",
       "  'trees\\n\\n': 426,\n",
       "  'trees\\nby': 468,\n",
       "  'trees\\nshe': 207,\n",
       "  \"trees\\nthere's\": 121,\n",
       "  'tried': 391,\n",
       "  'try': 280,\n",
       "  \"tryin'\": 162,\n",
       "  'trying': 195,\n",
       "  'turn': 214,\n",
       "  'two\\nand': 296,\n",
       "  'under': 136,\n",
       "  'understand': 390,\n",
       "  'up': 148,\n",
       "  'upon': 238,\n",
       "  'used': 463,\n",
       "  'very': 172,\n",
       "  'very\\nmerry': 378,\n",
       "  'wait': 309,\n",
       "  'waiting': 250,\n",
       "  'want': 40,\n",
       "  'was': 35,\n",
       "  \"way\\ni'd\": 269,\n",
       "  'way\\nthat': 180,\n",
       "  \"we're\": 104,\n",
       "  'weak\\n\\nwell': 546,\n",
       "  'week': 398,\n",
       "  'well': 72,\n",
       "  'well\\nbut': 457,\n",
       "  'were': 231,\n",
       "  'what': 150,\n",
       "  'when': 52,\n",
       "  'when\\nchristmas': 112,\n",
       "  'whenever': 326,\n",
       "  'who': 142,\n",
       "  'will': 24,\n",
       "  'will\\ni': 342,\n",
       "  'wind': 200,\n",
       "  'wire\\nnever': 525,\n",
       "  'wish': 169,\n",
       "  'wish\\nyourself': 368,\n",
       "  'with': 324,\n",
       "  'with\\nand': 253,\n",
       "  \"won't\": 119,\n",
       "  'wood\\nwhere': 447,\n",
       "  'woods\\namong': 442,\n",
       "  'world': 140,\n",
       "  'world\\nyes': 294,\n",
       "  'write': 455,\n",
       "  'yeah': 423,\n",
       "  'yeah\\n\\nhey': 258,\n",
       "  'year': 173,\n",
       "  'yes': 532,\n",
       "  'you': 4,\n",
       "  'you\\nand': 507,\n",
       "  'you\\nfor': 338,\n",
       "  'you\\nhow': 536,\n",
       "  'you\\ni': 315,\n",
       "  \"you\\ni'm\": 36,\n",
       "  'you\\nmake': 335,\n",
       "  'you\\ntell': 123,\n",
       "  'you\\nyou': 307,\n",
       "  'you\\nyour': 331,\n",
       "  \"you'd\": 290,\n",
       "  \"you'll\": 145,\n",
       "  'young': 449,\n",
       "  'your': 21})"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index), tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n' missing\n",
      "'songbegin' missing\n",
      "'songend' missing\n"
     ]
    }
   ],
   "source": [
    "lookfor = ['\\n', '<unk>', 'songbegin', 'songend']\n",
    "for L in lookfor:\n",
    "    if not L in tokenizer.word_index:\n",
    "        print(repr(L), 'missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "index_to_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>',\n",
       " 1: 'nah',\n",
       " 2: 'the',\n",
       " 3: 'to',\n",
       " 4: 'you',\n",
       " 5: 'go',\n",
       " 6: 'i',\n",
       " 7: 'a',\n",
       " 8: 'me',\n",
       " 9: 'is',\n",
       " 10: 'hey',\n",
       " 11: 'and',\n",
       " 12: 'on',\n",
       " 13: 'my',\n",
       " 14: 'time',\n",
       " 15: 'johnny',\n",
       " 16: 'here',\n",
       " 17: 'it',\n",
       " 18: 'jude\\nnah',\n",
       " 19: 'all',\n",
       " 20: 'make',\n",
       " 21: 'your',\n",
       " 22: 'be',\n",
       " 23: \"i'm\",\n",
       " 24: 'will',\n",
       " 25: 'nothing',\n",
       " 26: 'shaking\\nbut',\n",
       " 27: 'leaves',\n",
       " 28: \"don't\",\n",
       " 29: 'her',\n",
       " 30: 'get',\n",
       " 31: 'that',\n",
       " 32: 'glad',\n",
       " 33: 'let',\n",
       " 34: 'just',\n",
       " 35: 'was',\n",
       " 36: \"you\\ni'm\",\n",
       " 37: 'again\\nchristmas',\n",
       " 38: '\\ngo',\n",
       " 39: 'out',\n",
       " 40: 'want',\n",
       " 41: 'like',\n",
       " 42: \"\\nthere's\",\n",
       " 43: 'tell',\n",
       " 44: 'jude',\n",
       " 45: 'feel',\n",
       " 46: 'know',\n",
       " 47: \"didn't\",\n",
       " 48: 'of',\n",
       " 49: 'in',\n",
       " 50: 'for',\n",
       " 51: 'better',\n",
       " 52: 'when',\n",
       " 53: '\\n\\n',\n",
       " 54: 'hurt',\n",
       " 55: 'baby',\n",
       " 56: 'she',\n",
       " 57: 'but',\n",
       " 58: 'skelter',\n",
       " 59: 'can',\n",
       " 60: 'got',\n",
       " 61: 'so',\n",
       " 62: 'see',\n",
       " 63: 'love',\n",
       " 64: 'jealous',\n",
       " 65: 'trees',\n",
       " 66: 'down',\n",
       " 67: 'b',\n",
       " 68: 'dang',\n",
       " 69: \"gilly\\nit's\",\n",
       " 70: 'silly\\nbut',\n",
       " 71: 'made',\n",
       " 72: 'well',\n",
       " 73: 'his',\n",
       " 74: \"i've\",\n",
       " 75: \"can't\",\n",
       " 76: \"i'll\",\n",
       " 77: 'cry',\n",
       " 78: 'back',\n",
       " 79: 'break',\n",
       " 80: 'round',\n",
       " 81: 'at',\n",
       " 82: 'christmas',\n",
       " 83: 'please',\n",
       " 84: 'bottom',\n",
       " 85: 'coming',\n",
       " 86: 'fast',\n",
       " 87: \"ain't\",\n",
       " 88: 'no',\n",
       " 89: 'helter',\n",
       " 90: 'goode',\n",
       " 91: 'hot',\n",
       " 92: 'sad',\n",
       " 93: 'song',\n",
       " 94: 'start',\n",
       " 95: 'fool',\n",
       " 96: 'plays',\n",
       " 97: 'could',\n",
       " 98: 'locked',\n",
       " 99: 'people',\n",
       " 100: 'gonna',\n",
       " 101: 'come',\n",
       " 102: 'again',\n",
       " 103: 'do',\n",
       " 104: \"we're\",\n",
       " 105: 'heart',\n",
       " 106: 'mean',\n",
       " 107: 'sorry',\n",
       " 108: 'cry\\noh',\n",
       " 109: \"again\\n\\nain't\",\n",
       " 110: 'been',\n",
       " 111: 'since',\n",
       " 112: 'when\\nchristmas',\n",
       " 113: '\\n\\nthis',\n",
       " 114: \"i'd\",\n",
       " 115: 'new',\n",
       " 116: '\\ni',\n",
       " 117: 'knees',\n",
       " 118: 'give',\n",
       " 119: \"won't\",\n",
       " 120: 'sun',\n",
       " 121: \"trees\\nthere's\",\n",
       " 122: 'stop',\n",
       " 123: 'you\\ntell',\n",
       " 124: 'answer\\nyou',\n",
       " 125: 'may',\n",
       " 126: 'lover',\n",
       " 127: 'dancer',\n",
       " 128: 'skelter\\nhelter',\n",
       " 129: '\\n\\nlook',\n",
       " 130: 'country',\n",
       " 131: '\\naah',\n",
       " 132: 'bad\\ntake',\n",
       " 133: 'better\\nremember',\n",
       " 134: 'into',\n",
       " 135: 'heart\\nthen',\n",
       " 136: 'under',\n",
       " 137: 'skin\\nthen',\n",
       " 138: 'begin',\n",
       " 139: 'carry',\n",
       " 140: 'world',\n",
       " 141: \"it's\",\n",
       " 142: 'who',\n",
       " 143: 'little',\n",
       " 144: 'have',\n",
       " 145: \"you'll\",\n",
       " 146: 'every',\n",
       " 147: 'myself',\n",
       " 148: 'up',\n",
       " 149: 'hide',\n",
       " 150: 'what',\n",
       " 151: 'ever',\n",
       " 152: 'catch',\n",
       " 153: 'never',\n",
       " 154: 'find',\n",
       " 155: 'hear',\n",
       " 156: 'began',\n",
       " 157: 'lose',\n",
       " 158: 'control\\ni',\n",
       " 159: 'guy\\ni',\n",
       " 160: 'shivering',\n",
       " 161: 'inside\\ni',\n",
       " 162: \"tryin'\",\n",
       " 163: 'swallowing',\n",
       " 164: 'pain\\ni',\n",
       " 165: 'again\\no',\n",
       " 166: 't',\n",
       " 167: 'spells',\n",
       " 168: '\\n\\nchristmas',\n",
       " 169: 'wish',\n",
       " 170: 'john',\n",
       " 171: 'lennon',\n",
       " 172: 'very',\n",
       " 173: 'year',\n",
       " 174: 'take',\n",
       " 175: 'this',\n",
       " 176: 'about',\n",
       " 177: 'told',\n",
       " 178: 'must',\n",
       " 179: \"\\n\\nshe's\",\n",
       " 180: 'way\\nthat',\n",
       " 181: 'makes',\n",
       " 182: 'act',\n",
       " 183: '\\nspent',\n",
       " 184: 'money',\n",
       " 185: '\\nthen',\n",
       " 186: 'cool',\n",
       " 187: 'kisses\\non',\n",
       " 188: 'bended',\n",
       " 189: '\\noh',\n",
       " 190: 'me\\nsome',\n",
       " 191: 'loving',\n",
       " 192: '\\nplease',\n",
       " 193: '\\n\\nthough',\n",
       " 194: 'keep',\n",
       " 195: 'trying',\n",
       " 196: 'hard\\nto',\n",
       " 197: 'mine',\n",
       " 198: '\\none',\n",
       " 199: 'day',\n",
       " 200: 'wind',\n",
       " 201: 'blow\\nand',\n",
       " 202: 'shine',\n",
       " 203: '\\ntill',\n",
       " 204: 'time\\nshe',\n",
       " 205: 'puts',\n",
       " 206: 'ease',\n",
       " 207: 'trees\\nshe',\n",
       " 208: 'heart\\nand',\n",
       " 209: 'threw',\n",
       " 210: 'away',\n",
       " 211: 'keys',\n",
       " 212: 'top',\n",
       " 213: 'slide\\nwhere',\n",
       " 214: 'turn',\n",
       " 215: 'ride\\ntill',\n",
       " 216: 'miles',\n",
       " 217: 'out\\nhelter',\n",
       " 218: '\\n\\nwell',\n",
       " 219: '\\nyes',\n",
       " 220: 'play',\n",
       " 221: 'over\\noo',\n",
       " 222: 'honey',\n",
       " 223: 'bonnie\\ngive',\n",
       " 224: 'one',\n",
       " 225: 'more',\n",
       " 226: 'time\\nevery',\n",
       " 227: 'do\\nwell',\n",
       " 228: 'over\\nooo',\n",
       " 229: 'better\\n\\nhey',\n",
       " 230: 'afraid\\nyou',\n",
       " 231: 'were',\n",
       " 232: 'her\\nthe',\n",
       " 233: 'minute',\n",
       " 234: 'better\\n\\nand',\n",
       " 235: 'anytime',\n",
       " 236: 'pain',\n",
       " 237: \"refrain\\ndon't\",\n",
       " 238: 'upon',\n",
       " 239: 'shoulders\\nfor',\n",
       " 240: 'cool\\nby',\n",
       " 241: 'making',\n",
       " 242: 'colder\\nnah',\n",
       " 243: 'nah\\n\\nhey',\n",
       " 244: 'down\\nyou',\n",
       " 245: 'found',\n",
       " 246: 'now',\n",
       " 247: 'her\\nremember',\n",
       " 248: 'better\\n\\nso',\n",
       " 249: \"begin\\nyou're\",\n",
       " 250: 'waiting',\n",
       " 251: 'someone',\n",
       " 252: 'perform',\n",
       " 253: 'with\\nand',\n",
       " 254: 'do\\nthe',\n",
       " 255: 'movement',\n",
       " 256: 'need',\n",
       " 257: 'shoulder\\nnah',\n",
       " 258: 'yeah\\n\\nhey',\n",
       " 259: 'it\\nbetter',\n",
       " 260: 'oh\\n\\nnah',\n",
       " 261: 'jude\\n\\n',\n",
       " 262: 'reason',\n",
       " 263: 'earth',\n",
       " 264: \"mad\\n'cause\",\n",
       " 265: 'lost',\n",
       " 266: 'only',\n",
       " 267: 'girl',\n",
       " 268: 'had\\nif',\n",
       " 269: \"way\\ni'd\",\n",
       " 270: 'today\\nbut',\n",
       " 271: \"instead\\n\\ni've\",\n",
       " 272: 'chip',\n",
       " 273: 'shoulder',\n",
       " 274: \"that's\",\n",
       " 275: 'bigger',\n",
       " 276: 'feet\\ni',\n",
       " 277: 'talk',\n",
       " 278: 'meet\\nif',\n",
       " 279: \"now\\ni'd\",\n",
       " 280: 'try',\n",
       " 281: 'somehow\\nbut',\n",
       " 282: \"instead\\n\\ndon't\",\n",
       " 283: \"there's\",\n",
       " 284: 'there\\ni',\n",
       " 285: 'shy',\n",
       " 286: 'they',\n",
       " 287: \"stare\\ni'm\",\n",
       " 288: 'away\\nbut',\n",
       " 289: 'someday\\n\\nand',\n",
       " 290: \"you'd\",\n",
       " 291: \"girls\\ni'm\",\n",
       " 292: 'their',\n",
       " 293: 'hearts',\n",
       " 294: 'world\\nyes',\n",
       " 295: 'them',\n",
       " 296: 'two\\nand',\n",
       " 297: 'show',\n",
       " 298: \"lovin'\",\n",
       " 299: 'man',\n",
       " 300: 'do\\nuntil',\n",
       " 301: 'then',\n",
       " 302: 'instead\\n\\n',\n",
       " 303: 'knows',\n",
       " 304: 'how',\n",
       " 305: 'long',\n",
       " 306: 'loved',\n",
       " 307: 'you\\nyou',\n",
       " 308: 'still\\nwill',\n",
       " 309: 'wait',\n",
       " 310: 'lonely',\n",
       " 311: 'lifetime\\nif',\n",
       " 312: '\\n\\nfor',\n",
       " 313: 'if',\n",
       " 314: 'saw',\n",
       " 315: 'you\\ni',\n",
       " 316: 'name\\nbut',\n",
       " 317: 'really',\n",
       " 318: 'mattered\\ni',\n",
       " 319: 'always',\n",
       " 320: 'same',\n",
       " 321: '\\n\\nlove',\n",
       " 322: 'forever',\n",
       " 323: 'forever\\nlove',\n",
       " 324: 'with',\n",
       " 325: 'heart\\nlove',\n",
       " 326: 'whenever',\n",
       " 327: 'together\\nlove',\n",
       " 328: 'apart',\n",
       " 329: '\\n\\nand',\n",
       " 330: 'last',\n",
       " 331: 'you\\nyour',\n",
       " 332: 'fill',\n",
       " 333: 'air\\nsing',\n",
       " 334: 'loud',\n",
       " 335: 'you\\nmake',\n",
       " 336: 'easy',\n",
       " 337: 'near',\n",
       " 338: 'you\\nfor',\n",
       " 339: 'things',\n",
       " 340: 'endear',\n",
       " 341: 'me\\nyou',\n",
       " 342: 'will\\ni',\n",
       " 343: 'dreaming',\n",
       " 344: 'past\\nand',\n",
       " 345: 'beating',\n",
       " 346: 'fast\\ni',\n",
       " 347: 'feeling',\n",
       " 348: 'insecure\\nyou',\n",
       " 349: 'might',\n",
       " 350: 'not',\n",
       " 351: 'any',\n",
       " 352: 'more\\ni',\n",
       " 353: 'eyes\\nthought',\n",
       " 354: 'hide\\ni',\n",
       " 355: 'guy\\nwatch',\n",
       " 356: \"out\\ni'm\",\n",
       " 357: 'guy\\nlook',\n",
       " 358: \"baby\\ni'm\",\n",
       " 359: 'guy\\n\\n',\n",
       " 360: 'music',\n",
       " 361: 'continues',\n",
       " 362: 'fades',\n",
       " 363: 'background',\n",
       " 364: 'spoken',\n",
       " 365: 'paul',\n",
       " 366: 'mccartney',\n",
       " 367: 'everything',\n",
       " 368: 'wish\\nyourself',\n",
       " 369: 'saying',\n",
       " 370: 'behalf',\n",
       " 371: 'beatles',\n",
       " 372: 'happy\\nchristmas',\n",
       " 373: 'good',\n",
       " 374: '\\n\\ngeorge',\n",
       " 375: 'harrison',\n",
       " 376: 'speaking',\n",
       " 377: 'opportunity',\n",
       " 378: 'very\\nmerry',\n",
       " 379: 'listeners',\n",
       " 380: 'everywhere',\n",
       " 381: 'ringo',\n",
       " 382: 'starr',\n",
       " 383: 'say',\n",
       " 384: 'merry',\n",
       " 385: 'really\\nhappy',\n",
       " 386: 'listeners\\n\\n',\n",
       " 387: 'pastiche',\n",
       " 388: 'point',\n",
       " 389: 'hard',\n",
       " 390: 'understand',\n",
       " 391: 'tried',\n",
       " 392: 'out\\nwhat',\n",
       " 393: '\\nand',\n",
       " 394: 'day\\nit',\n",
       " 395: 'sure',\n",
       " 396: 'lets',\n",
       " 397: 'baby\\ni',\n",
       " 398: 'week',\n",
       " 399: '\\nmy',\n",
       " 400: 'pappie',\n",
       " 401: \"me\\nthere'd\",\n",
       " 402: 'times',\n",
       " 403: 'these',\n",
       " 404: '\\n\\nwe',\n",
       " 405: 'meet',\n",
       " 406: 'gang\\nand',\n",
       " 407: 'rocking',\n",
       " 408: 'joes',\n",
       " 409: '\\nthe',\n",
       " 410: 'cats',\n",
       " 411: 'are',\n",
       " 412: 'something\\non',\n",
       " 413: 'heels',\n",
       " 414: 'toes',\n",
       " 415: 'grab',\n",
       " 416: '\\ntried',\n",
       " 417: 'squeeze',\n",
       " 418: '\\nwhy',\n",
       " 419: 'be\\nsuch',\n",
       " 420: 'doggone',\n",
       " 421: 'tease',\n",
       " 422: 'beg',\n",
       " 423: 'yeah',\n",
       " 424: \"\\ni'm\",\n",
       " 425: 'begging',\n",
       " 426: 'trees\\n\\n',\n",
       " 427: '\\n\\ndo',\n",
       " 428: 'above',\n",
       " 429: '\\n\\nhelter',\n",
       " 430: '\\n\\nwill',\n",
       " 431: '\\nlook',\n",
       " 432: \"'cause\",\n",
       " 433: 'comes',\n",
       " 434: '\\n\\nwhen',\n",
       " 435: \"skelter\\nshe's\",\n",
       " 436: 'is\\n\\n',\n",
       " 437: 'blisters',\n",
       " 438: 'fingers',\n",
       " 439: 'deep',\n",
       " 440: 'louisianna\\nclose',\n",
       " 441: 'orleans\\nway',\n",
       " 442: 'woods\\namong',\n",
       " 443: 'evergreens\\nthere',\n",
       " 444: 'stand',\n",
       " 445: 'cabin\\nmade',\n",
       " 446: 'clay',\n",
       " 447: 'wood\\nwhere',\n",
       " 448: 'lives',\n",
       " 449: 'young',\n",
       " 450: 'boy\\nnamed',\n",
       " 451: 'goode\\nhe',\n",
       " 452: 'learned\\nto',\n",
       " 453: 'read',\n",
       " 454: 'or',\n",
       " 455: 'write',\n",
       " 456: 'book',\n",
       " 457: 'well\\nbut',\n",
       " 458: 'he',\n",
       " 459: 'guitar\\njust',\n",
       " 460: 'ringing',\n",
       " 461: 'bell\\n\\ngo',\n",
       " 462: '\\n\\nhe',\n",
       " 463: 'used',\n",
       " 464: 'guitar\\nin',\n",
       " 465: 'gunny',\n",
       " 466: 'sack\\nsit',\n",
       " 467: 'beneath',\n",
       " 468: 'trees\\nby',\n",
       " 469: 'railroad',\n",
       " 470: 'track\\noh',\n",
       " 471: 'sitting',\n",
       " 472: 'playing\\nin',\n",
       " 473: 'shade\\ndrumming',\n",
       " 474: 'rhythm\\nthat',\n",
       " 475: 'drivers',\n",
       " 476: 'made\\npeople',\n",
       " 477: 'passing',\n",
       " 478: 'by\\nused',\n",
       " 479: 'say\\nmy',\n",
       " 480: 'oh',\n",
       " 481: 'my\\nthat',\n",
       " 482: 'boy',\n",
       " 483: 'play\\n\\ngo',\n",
       " 484: 'mama',\n",
       " 485: 'him\\nsomeday',\n",
       " 486: 'man\\nand',\n",
       " 487: 'leader\\nof',\n",
       " 488: 'big',\n",
       " 489: 'old',\n",
       " 490: 'band\\nmany',\n",
       " 491: 'coming\\nfrom',\n",
       " 492: 'around\\nto',\n",
       " 493: 'music\\ntill',\n",
       " 494: 'goes',\n",
       " 495: 'down\\nmaybe',\n",
       " 496: 'some',\n",
       " 497: 'day\\nyour',\n",
       " 498: 'name',\n",
       " 499: 'light\\nsaying',\n",
       " 500: 'tonight',\n",
       " 501: '\\n\\ngo',\n",
       " 502: 'doubt',\n",
       " 503: 'it\\nthis',\n",
       " 504: 'love\\none',\n",
       " 505: 'kiss',\n",
       " 506: 'from',\n",
       " 507: 'you\\nand',\n",
       " 508: 'over\\n\\nyeah',\n",
       " 509: 'goosepimples',\n",
       " 510: \"baby\\n'cause\",\n",
       " 511: 'good\\nwhen',\n",
       " 512: 'call',\n",
       " 513: 'do\\nand',\n",
       " 514: 'mercy',\n",
       " 515: 'rock',\n",
       " 516: 'gone',\n",
       " 517: 'puppy\\nand',\n",
       " 518: 'happy\\nand',\n",
       " 519: 'over\\n\\nyour',\n",
       " 520: 'touch',\n",
       " 521: 'sewed',\n",
       " 522: 'me\\nlike',\n",
       " 523: 'an',\n",
       " 524: 'electric',\n",
       " 525: 'wire\\nnever',\n",
       " 526: 'thought',\n",
       " 527: 'love\\nit',\n",
       " 528: 'much',\n",
       " 529: 'looking\\nto',\n",
       " 530: 'got\\nbut',\n",
       " 531: 'shows',\n",
       " 532: 'yes',\n",
       " 533: 'shows\\ncome',\n",
       " 534: 'over\\nyeah',\n",
       " 535: '\\n\\ntried',\n",
       " 536: 'you\\nhow',\n",
       " 537: 'cooking',\n",
       " 538: 'inside\\nwhen',\n",
       " 539: 'cheek',\n",
       " 540: 'cheek\\nmy',\n",
       " 541: 'temperature',\n",
       " 542: 'low\\nfever',\n",
       " 543: 'high\\ni',\n",
       " 544: \"speak\\ni'm\",\n",
       " 545: 'too',\n",
       " 546: 'weak\\n\\nwell',\n",
       " 547: 'over\\nhot',\n",
       " 548: 'over\\nwell',\n",
       " 549: 'over',\n",
       " 550: '<unk>'}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.num_words = min(len(tokenizer.word_index)+1, tokenizer.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = text_generator(files)\n",
    "text = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am he as you are he as you are me and we are all together.\\nSee how they run like pigs from a gun, see how they fly.\\nI'm crying.\\n\\nSitting on a cornflake, waiting for the van to come.\\nCorporation tee-shirt, stupid bloody Tuesday.\\nMan, you been a naughty boy, you let your face grow long.\\nI am the egg man, they are the egg men.\\nI am the walrus, coo coo cachoo\\n\\nMister City Policeman sitting\\nPretty little policemen in a row.\\nSee how they fly like Lucy in the Sky, see how they run.\\nI'm crying, I'm crying.\\nI'm crying, I'm crying.\\n\\nYellow matter custard, dripping from a dead dog's eye.\\nCrabalocker fishwife, pornographic priestess,\\nBoy, you been a naughty girl you let your knickers down.\\nI am the eggman, they are the eggmen.\\nI am the walrus, coo coo cachoo\\n\\nSitting in an English garden waiting for the sun.\\nIf the sun don't come, you get a tan\\nFrom standing in the English rain.\\nI am the egg man, they are the egg men.\\nI am the walrus, coo coo cachoo ca coo coo cachoo\\n\\nExpert text pert choking smokers,\\nDon't you think the joker laughs at you?\\nSee how they smile like pigs in a sty,\\nSee how they snide.\\nI'm crying.\\n\\nSemolina pilchard, climbing up the Eiffel Tower.\\nElementary penguin singing Hari Krishna.\\nMan, you should have seen them kicking Edgar Allan Poe.\\nI am the egg man, they are the egg men.\\nI am the walrus, coo coo cachoo ca coo coo cachoo. Coo coo cachou ca coo.\\n\\n\""
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 550, 458, 550, 4, 411, 458, 550, 4, 411, 8, 11, 550, 411, 19, 550],\n",
       " [62, 304, 286, 550, 41, 550, 506, 7, 550, 62, 304, 286, 550],\n",
       " [23, 550],\n",
       " [],\n",
       " [471, 12, 7, 550, 250, 50, 2, 550, 3, 101],\n",
       " [550, 550, 550, 550, 550, 550],\n",
       " [299, 4, 110, 7, 550, 482, 4, 33, 21, 550, 550, 305],\n",
       " [6, 550, 2, 550, 299, 286, 411, 2, 550, 550],\n",
       " [6, 550, 2, 550, 550, 550, 550],\n",
       " [],\n",
       " [550, 550, 550, 471],\n",
       " [550, 143, 550, 49, 7, 550],\n",
       " [62, 304, 286, 550, 41, 550, 49, 2, 550, 62, 304, 286, 550],\n",
       " [23, 550, 23, 550],\n",
       " [23, 550, 23, 550],\n",
       " [],\n",
       " [550, 550, 550, 550, 506, 7, 550, 550, 550],\n",
       " [550, 550, 550, 550],\n",
       " [482, 4, 110, 7, 550, 267, 4, 33, 21, 550, 66],\n",
       " [6, 550, 2, 550, 286, 411, 2, 550],\n",
       " [6, 550, 2, 550, 550, 550, 550],\n",
       " [],\n",
       " [471, 49, 523, 550, 550, 250, 50, 2, 120],\n",
       " [313, 2, 120, 28, 101, 4, 30, 7, 550],\n",
       " [506, 550, 49, 2, 550, 550],\n",
       " [6, 550, 2, 550, 299, 286, 411, 2, 550, 550],\n",
       " [6, 550, 2, 550, 550, 550, 550, 550, 550, 550, 550],\n",
       " [],\n",
       " [550, 550, 550, 550, 550],\n",
       " [28, 4, 550, 2, 550, 550, 81, 4],\n",
       " [62, 304, 286, 550, 41, 550, 49, 7, 550],\n",
       " [62, 304, 286, 550],\n",
       " [23, 550],\n",
       " [],\n",
       " [550, 550, 550, 148, 2, 550, 550],\n",
       " [550, 550, 550, 550, 550],\n",
       " [299, 4, 550, 144, 550, 295, 550, 550, 550, 550],\n",
       " [6, 550, 2, 550, 299, 286, 411, 2, 550, 550],\n",
       " [6, 550, 2, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(text.split('\\n'))\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  '<unk>',\n",
       "  'he',\n",
       "  '<unk>',\n",
       "  'you',\n",
       "  'are',\n",
       "  'he',\n",
       "  '<unk>',\n",
       "  'you',\n",
       "  'are',\n",
       "  'me',\n",
       "  'and',\n",
       "  '<unk>',\n",
       "  'are',\n",
       "  'all',\n",
       "  '<unk>'],\n",
       " ['see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>',\n",
       "  'like',\n",
       "  '<unk>',\n",
       "  'from',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>'],\n",
       " [\"i'm\", '<unk>'],\n",
       " [],\n",
       " ['sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'to',\n",
       "  'come'],\n",
       " ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " ['man',\n",
       "  'you',\n",
       "  'been',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'boy',\n",
       "  'you',\n",
       "  'let',\n",
       "  'your',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'long'],\n",
       " ['i', '<unk>', 'the', '<unk>', 'man', 'they', 'are', 'the', '<unk>', '<unk>'],\n",
       " ['i', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " [],\n",
       " ['<unk>', '<unk>', '<unk>', 'sitting'],\n",
       " ['<unk>', 'little', '<unk>', 'in', 'a', '<unk>'],\n",
       " ['see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>',\n",
       "  'like',\n",
       "  '<unk>',\n",
       "  'in',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>'],\n",
       " [\"i'm\", '<unk>', \"i'm\", '<unk>'],\n",
       " [\"i'm\", '<unk>', \"i'm\", '<unk>'],\n",
       " [],\n",
       " ['<unk>', '<unk>', '<unk>', '<unk>', 'from', 'a', '<unk>', '<unk>', '<unk>'],\n",
       " ['<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " ['boy',\n",
       "  'you',\n",
       "  'been',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'girl',\n",
       "  'you',\n",
       "  'let',\n",
       "  'your',\n",
       "  '<unk>',\n",
       "  'down'],\n",
       " ['i', '<unk>', 'the', '<unk>', 'they', 'are', 'the', '<unk>'],\n",
       " ['i', '<unk>', 'the', '<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " [],\n",
       " ['sitting', 'in', 'an', '<unk>', '<unk>', 'waiting', 'for', 'the', 'sun'],\n",
       " ['if', 'the', 'sun', \"don't\", 'come', 'you', 'get', 'a', '<unk>'],\n",
       " ['from', '<unk>', 'in', 'the', '<unk>', '<unk>'],\n",
       " ['i', '<unk>', 'the', '<unk>', 'man', 'they', 'are', 'the', '<unk>', '<unk>'],\n",
       " ['i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " [],\n",
       " ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " [\"don't\", 'you', '<unk>', 'the', '<unk>', '<unk>', 'at', 'you'],\n",
       " ['see', 'how', 'they', '<unk>', 'like', '<unk>', 'in', 'a', '<unk>'],\n",
       " ['see', 'how', 'they', '<unk>'],\n",
       " [\"i'm\", '<unk>'],\n",
       " [],\n",
       " ['<unk>', '<unk>', '<unk>', 'up', 'the', '<unk>', '<unk>'],\n",
       " ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>'],\n",
       " ['man',\n",
       "  'you',\n",
       "  '<unk>',\n",
       "  'have',\n",
       "  '<unk>',\n",
       "  'them',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['i', '<unk>', 'the', '<unk>', 'man', 'they', 'are', 'the', '<unk>', '<unk>'],\n",
       " ['i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[index_to_word[i] for i in L] for L in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 16)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence), len(sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6, 550, 458, 550,   4, 411, 458, 550,   4, 411,   8,  11, 550,\n",
       "        411,  19, 550],\n",
       "       [  0,   0,   0,  62, 304, 286, 550,  41, 550, 506,   7, 550,  62,\n",
       "        304, 286, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  23, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 471,  12,   7, 550, 250,  50,   2,\n",
       "        550,   3, 101],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550, 550, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0, 299,   4, 110,   7, 550, 482,   4,  33,  21,\n",
       "        550, 550, 305],\n",
       "       [  0,   0,   0,   0,   0,   0,   6, 550,   2, 550, 299, 286, 411,\n",
       "          2, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   6, 550,   2, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,\n",
       "        550, 550, 471],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550, 143, 550,\n",
       "         49,   7, 550],\n",
       "       [  0,   0,   0,  62, 304, 286, 550,  41, 550,  49,   2, 550,  62,\n",
       "        304, 286, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,\n",
       "        550,  23, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,\n",
       "        550,  23, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 550, 550, 550, 550, 506,   7,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0, 482,   4, 110,   7, 550, 267,   4,  33,\n",
       "         21, 550,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   6, 550,   2, 550, 286,\n",
       "        411,   2, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   6, 550,   2, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 471,  49, 523, 550, 550, 250,\n",
       "         50,   2, 120],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 313,   2, 120,  28, 101,   4,\n",
       "         30,   7, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 506, 550,  49,\n",
       "          2, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   6, 550,   2, 550, 299, 286, 411,\n",
       "          2, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   6, 550,   2, 550, 550, 550, 550, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  28,   4, 550,   2, 550,\n",
       "        550,  81,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  62, 304, 286, 550,  41, 550,\n",
       "         49,   7, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  62,\n",
       "        304, 286, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  23, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 550, 550, 550, 148,\n",
       "          2, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0, 299,   4, 550, 144, 550, 295, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   6, 550,   2, 550, 299, 286, 411,\n",
       "          2, 550, 550],\n",
       "       [  6, 550,   2, 550, 550, 550, 550, 550, 550, 550, 550, 550, 550,\n",
       "        550, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_sequences(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  '<unk>',\n",
       "  'he',\n",
       "  '<unk>',\n",
       "  'you',\n",
       "  'are',\n",
       "  'he',\n",
       "  '<unk>',\n",
       "  'you',\n",
       "  'are',\n",
       "  'me',\n",
       "  'and',\n",
       "  '<unk>',\n",
       "  'are',\n",
       "  'all',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>',\n",
       "  'like',\n",
       "  '<unk>',\n",
       "  'from',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  \"i'm\",\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'to',\n",
       "  'come'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'man',\n",
       "  'you',\n",
       "  'been',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'boy',\n",
       "  'you',\n",
       "  'let',\n",
       "  'your',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'long'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'man',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'sitting'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  'little',\n",
       "  '<unk>',\n",
       "  'in',\n",
       "  'a',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>',\n",
       "  'like',\n",
       "  '<unk>',\n",
       "  'in',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  \"i'm\",\n",
       "  '<unk>',\n",
       "  \"i'm\",\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  \"i'm\",\n",
       "  '<unk>',\n",
       "  \"i'm\",\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'from',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'boy',\n",
       "  'you',\n",
       "  'been',\n",
       "  'a',\n",
       "  '<unk>',\n",
       "  'girl',\n",
       "  'you',\n",
       "  'let',\n",
       "  'your',\n",
       "  '<unk>',\n",
       "  'down'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'sitting',\n",
       "  'in',\n",
       "  'an',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'the',\n",
       "  'sun'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'if',\n",
       "  'the',\n",
       "  'sun',\n",
       "  \"don't\",\n",
       "  'come',\n",
       "  'you',\n",
       "  'get',\n",
       "  'a',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'from',\n",
       "  '<unk>',\n",
       "  'in',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'man',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  \"don't\",\n",
       "  'you',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'at',\n",
       "  'you'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>',\n",
       "  'like',\n",
       "  '<unk>',\n",
       "  'in',\n",
       "  'a',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'see',\n",
       "  'how',\n",
       "  'they',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  \"i'm\",\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'up',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'man',\n",
       "  'you',\n",
       "  '<unk>',\n",
       "  'have',\n",
       "  '<unk>',\n",
       "  'them',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  'man',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['i',\n",
       "  '<unk>',\n",
       "  'the',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>']]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[index_to_word[i] for i in x] for x in pad_sequences(sequence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 550, 458, 550, 4, 411, 458, 550, 4, 411, 8, 11, 550, 411, 19, 550]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sequence[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = tokenizer.sequences_to_matrix([[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6],\n",
       "       [  1, 550],\n",
       "       [  2, 458],\n",
       "       [  3, 550],\n",
       "       [  4,   4],\n",
       "       [  5, 411],\n",
       "       [  6, 458],\n",
       "       [  7, 550],\n",
       "       [  8,   4],\n",
       "       [  9, 411],\n",
       "       [ 10,   8],\n",
       "       [ 11,  11],\n",
       "       [ 12, 550],\n",
       "       [ 13, 411],\n",
       "       [ 14,  19],\n",
       "       [ 15, 550]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only one per row\n",
    "import numpy as np\n",
    "np.argwhere(one_hot == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = lambda x: x.split('\\n')\n",
    "splitter = lambda x: [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencer(tokens):\n",
    "    return [tokens[:i] for i in range(1, len(tokens)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a ',\n",
       " 'a q',\n",
       " 'a qu',\n",
       " 'a qui',\n",
       " 'a quic',\n",
       " 'a quick',\n",
       " 'a quick ',\n",
       " 'a quick b',\n",
       " 'a quick br',\n",
       " 'a quick bro',\n",
       " 'a quick brow',\n",
       " 'a quick brown',\n",
       " 'a quick brown ',\n",
       " 'a quick brown f',\n",
       " 'a quick brown fo',\n",
       " 'a quick brown fox']"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sequencer('a quick brown fox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def batch_generator(files, tokenizer, maxlen=30, batch_size=32, splitter=None,\n",
    "                    sequencer=None, preprocessor=None, epoch_end=None):\n",
    "    batch_sequences = []\n",
    "    while True:\n",
    "        random.shuffle(files)\n",
    "        for text in text_generator(files, splitter, preprocessor):\n",
    "            tokens = tokenizer.texts_to_sequences([text])[0]\n",
    "            sequences = sequencer(tokens)\n",
    "            batch_sequences.extend(sequences)\n",
    "            \n",
    "            while len(batch_sequences) >= batch_size:\n",
    "                X = pad_sequences(batch_sequences[:batch_size], maxlen=maxlen)\n",
    "                y = tokenizer.sequences_to_matrix([[i] for seq in X for i in seq])\n",
    "                y = y.reshape((batch_size, maxlen, tokenizer.num_words))\n",
    "                \n",
    "                # offset input/output\n",
    "                X = [X[:-1], X[:-1]]\n",
    "                y = y[1:]\n",
    "                \n",
    "                # reset\n",
    "                batch_sequences = batch_sequences[batch_size:]\n",
    "                \n",
    "                yield X, y\n",
    "    \n",
    "        if epoch_end is not None:\n",
    "            yield epoch_end\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "batch_gen = batch_generator(files, tokenizer, 30, splitter=splitter, sequencer=sequencer, preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31, 30), (31, 30), (31, 30, 551))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, X[1].shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 550,  74],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 550,  74,  60],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        550,  74,  60, 146],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,\n",
       "         74,  60, 146, 262],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,\n",
       "         60, 146, 262,  12],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60,\n",
       "        146, 262,  12, 263],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146,\n",
       "        262,  12, 263,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,\n",
       "         12, 263,   3,  22],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12,\n",
       "        263,   3,  22, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,\n",
       "          3,  22, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,\n",
       "         22, 550, 550, 432],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22,\n",
       "        550, 550, 432,   6],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550,\n",
       "        550, 432,   6,  34],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550,\n",
       "        432,   6,  34, 265],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,\n",
       "          6,  34, 265,   2],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,   6,\n",
       "         34, 265,   2, 266],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,\n",
       "         74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,   6,  34,\n",
       "        265,   2, 266, 267],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,\n",
       "         60, 146, 262,  12, 263,   3,  22, 550, 550, 432,   6,  34, 265,\n",
       "          2, 266, 267,   6],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60,\n",
       "        146, 262,  12, 263,   3,  22, 550, 550, 432,   6,  34, 265,   2,\n",
       "        266, 267,   6, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146,\n",
       "        262,  12, 263,   3,  22, 550, 550, 432,   6,  34, 265,   2, 266,\n",
       "        267,   6, 550, 550],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,\n",
       "         12, 263,   3,  22, 550, 550, 432,   6,  34, 265,   2, 266, 267,\n",
       "          6, 550, 550, 313],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12,\n",
       "        263,   3,  22, 550, 550, 432,   6,  34, 265,   2, 266, 267,   6,\n",
       "        550, 550, 313,   6],\n",
       "       [  0,   0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,\n",
       "          3,  22, 550, 550, 432,   6,  34, 265,   2, 266, 267,   6, 550,\n",
       "        550, 313,   6,  97],\n",
       "       [  0,   0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,\n",
       "         22, 550, 550, 432,   6,  34, 265,   2, 266, 267,   6, 550, 550,\n",
       "        313,   6,  97,  30],\n",
       "       [  0,   0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22,\n",
       "        550, 550, 432,   6,  34, 265,   2, 266, 267,   6, 550, 550, 313,\n",
       "          6,  97,  30,  13],\n",
       "       [  0,   0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550,\n",
       "        550, 432,   6,  34, 265,   2, 266, 267,   6, 550, 550, 313,   6,\n",
       "         97,  30,  13, 550],\n",
       "       [  0,   0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550,\n",
       "        432,   6,  34, 265,   2, 266, 267,   6, 550, 550, 313,   6,  97,\n",
       "         30,  13, 550, 550],\n",
       "       [  0, 550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,\n",
       "          6,  34, 265,   2, 266, 267,   6, 550, 550, 313,   6,  97,  30,\n",
       "         13, 550, 550, 114],\n",
       "       [550,  74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,   6,\n",
       "         34, 265,   2, 266, 267,   6, 550, 550, 313,   6,  97,  30,  13,\n",
       "        550, 550, 114,  30],\n",
       "       [ 74,  60, 146, 262,  12, 263,   3,  22, 550, 550, 432,   6,  34,\n",
       "        265,   2, 266, 267,   6, 550, 550, 313,   6,  97,  30,  13, 550,\n",
       "        550, 114,  30, 147]], dtype=int32)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2 = X\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\"],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\"],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my',\n",
       "  '<unk>',\n",
       "  '<unk>'],\n",
       " ['<pad>',\n",
       "  '<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"i'd\"],\n",
       " ['<unk>',\n",
       "  \"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"i'd\",\n",
       "  'get'],\n",
       " [\"i've\",\n",
       "  'got',\n",
       "  'every',\n",
       "  'reason',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'to',\n",
       "  'be',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"'cause\",\n",
       "  'i',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'only',\n",
       "  'girl',\n",
       "  'i',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  'if',\n",
       "  'i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'my',\n",
       "  '<unk>',\n",
       "  '<unk>',\n",
       "  \"i'd\",\n",
       "  'get',\n",
       "  'myself']]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[index_to_word.get(i, '<pad>') for i in x] for x in x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 8\n",
    "n_layers = 6\n",
    "d_model = 64*n_heads\n",
    "vocab_size = tokenizer.num_words\n",
    "sequence_len = 10\n",
    "warmup_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = batch_generator(\n",
    "    files, tokenizer, sequence_len, splitter=splitter,\n",
    "    sequencer=sequencer, preprocessor=preprocessor, epoch_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over batch generator until we hit the end of the epoch\n",
    "# to calculate number of batches in epoch and compute some\n",
    "# stats along the way\n",
    "steps_per_epoch = 0\n",
    "for batch in batch_gen:\n",
    "    if batch == 0:\n",
    "        break\n",
    "    steps_per_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps per epoch 83\n"
     ]
    }
   ],
   "source": [
    "print('steps per epoch', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = (X for X in batch_gen if not X == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TerminateOnNaN\n",
    "callbacks = [TerminateOnNaN()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "model = Transformer(\n",
    "        n_heads=n_heads, encoder_layers=n_layers, decoder_layers=n_layers,\n",
    "        d_model=d_model, vocab_size=vocab_size, sequence_len=sequence_len,\n",
    "        layer_normalization=True, dropout=True,\n",
    "        residual_connections=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 512)      282112      encoder_input[0][0]              \n",
      "                                                                 decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_5 (Position (None, 10, 512)      0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_scalar (Scalar)       (None, 10, 512)      0           positional_encoding_5[0][0]      \n",
      "                                                                 positional_encoding_5[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 10, 512)      0           embedding_scalar[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_mha (MultiHeadAt (None, 10, 512)      262144      dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 10, 512)      0           encoder_layer1_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual1 (Add)  (None, 10, 512)      0           dropout_129[0][0]                \n",
      "                                                                 dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer1_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 10, 512)      0           encoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_residual2 (Add)  (None, 10, 512)      0           encoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer1_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_mha (MultiHeadAt (None, 10, 512)      262144      encoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 10, 512)      0           encoder_layer2_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual1 (Add)  (None, 10, 512)      0           encoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer2_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 10, 512)      0           encoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_residual2 (Add)  (None, 10, 512)      0           encoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer2_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_mha (MultiHeadAt (None, 10, 512)      262144      encoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 10, 512)      0           encoder_layer3_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual1 (Add)  (None, 10, 512)      0           encoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer3_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 10, 512)      0           encoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_residual2 (Add)  (None, 10, 512)      0           encoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer3_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_mha (MultiHeadAt (None, 10, 512)      262144      encoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 10, 512)      0           encoder_layer4_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual1 (Add)  (None, 10, 512)      0           encoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer4_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 10, 512)      0           encoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_residual2 (Add)  (None, 10, 512)      0           encoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer4_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_mha (MultiHeadAt (None, 10, 512)      262144      encoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 10, 512)      0           encoder_layer5_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_residual1 (Add)  (None, 10, 512)      0           encoder_layer4_layernorm2[0][0]  \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer5_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer5_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer5_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 10, 512)      0           encoder_layer5_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_residual2 (Add)  (None, 10, 512)      0           encoder_layer5_layernorm1[0][0]  \n",
      "                                                                 dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer5_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer5_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_mha (MultiHeadAt (None, 10, 512)      262144      encoder_layer5_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 10, 512)      0           encoder_layer6_mha[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_residual1 (Add)  (None, 10, 512)      0           encoder_layer5_layernorm2[0][0]  \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_layernorm1 (Laye (None, 10, 512)      10240       encoder_layer6_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 10, 512)      0           embedding_scalar[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_ffn1 (Dense)     (None, 10, 512)      262656      encoder_layer6_layernorm1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha1 (MultiHeadA (None, 10, 512)      262144      dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_ffn2 (Dense)     (None, 10, 512)      262656      encoder_layer6_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 10, 512)      0           decoder_layer1_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 10, 512)      0           encoder_layer6_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual1 (Add)  (None, 10, 512)      0           dropout_130[0][0]                \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_residual2 (Add)  (None, 10, 512)      0           encoder_layer6_layernorm1[0][0]  \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer1_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_layer6_layernorm2 (Laye (None, 10, 512)      10240       encoder_layer6_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 10, 512)      0           decoder_layer1_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual2 (Add)  (None, 10, 512)      0           decoder_layer1_layernorm1[0][0]  \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer1_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer1_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer1_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 10, 512)      0           decoder_layer1_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_residual3 (Add)  (None, 10, 512)      0           decoder_layer1_layernorm2[0][0]  \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer1_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer1_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha1 (MultiHeadA (None, 10, 512)      262144      decoder_layer1_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 10, 512)      0           decoder_layer2_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual1 (Add)  (None, 10, 512)      0           decoder_layer1_layernorm3[0][0]  \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer2_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 10, 512)      0           decoder_layer2_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual2 (Add)  (None, 10, 512)      0           decoder_layer2_layernorm1[0][0]  \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer2_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer2_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer2_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 10, 512)      0           decoder_layer2_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_residual3 (Add)  (None, 10, 512)      0           decoder_layer2_layernorm2[0][0]  \n",
      "                                                                 dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer2_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer2_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha1 (MultiHeadA (None, 10, 512)      262144      decoder_layer2_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 10, 512)      0           decoder_layer3_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual1 (Add)  (None, 10, 512)      0           decoder_layer2_layernorm3[0][0]  \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer3_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 10, 512)      0           decoder_layer3_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual2 (Add)  (None, 10, 512)      0           decoder_layer3_layernorm1[0][0]  \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer3_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer3_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer3_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 10, 512)      0           decoder_layer3_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_residual3 (Add)  (None, 10, 512)      0           decoder_layer3_layernorm2[0][0]  \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer3_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer3_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha1 (MultiHeadA (None, 10, 512)      262144      decoder_layer3_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 10, 512)      0           decoder_layer4_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual1 (Add)  (None, 10, 512)      0           decoder_layer3_layernorm3[0][0]  \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer4_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 10, 512)      0           decoder_layer4_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual2 (Add)  (None, 10, 512)      0           decoder_layer4_layernorm1[0][0]  \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer4_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer4_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer4_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 10, 512)      0           decoder_layer4_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_residual3 (Add)  (None, 10, 512)      0           decoder_layer4_layernorm2[0][0]  \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer4_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer4_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_mha1 (MultiHeadA (None, 10, 512)      262144      decoder_layer4_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 10, 512)      0           decoder_layer5_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual1 (Add)  (None, 10, 512)      0           decoder_layer4_layernorm3[0][0]  \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer5_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer5_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 10, 512)      0           decoder_layer5_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual2 (Add)  (None, 10, 512)      0           decoder_layer5_layernorm1[0][0]  \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer5_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer5_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer5_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 10, 512)      0           decoder_layer5_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_residual3 (Add)  (None, 10, 512)      0           decoder_layer5_layernorm2[0][0]  \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer5_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer5_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_mha1 (MultiHeadA (None, 10, 512)      262144      decoder_layer5_layernorm3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 10, 512)      0           decoder_layer6_mha1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual1 (Add)  (None, 10, 512)      0           decoder_layer5_layernorm3[0][0]  \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm1 (Laye (None, 10, 512)      10240       decoder_layer6_residual1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_mha2 (MultiHeadA (None, 10, 512)      262144      decoder_layer6_layernorm1[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "                                                                 encoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 10, 512)      0           decoder_layer6_mha2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual2 (Add)  (None, 10, 512)      0           decoder_layer6_layernorm1[0][0]  \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm2 (Laye (None, 10, 512)      10240       decoder_layer6_residual2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_ffn1 (Dense)     (None, 10, 512)      262656      decoder_layer6_layernorm2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_ffn2 (Dense)     (None, 10, 512)      262656      decoder_layer6_ffn1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 10, 512)      0           decoder_layer6_ffn2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_residual3 (Add)  (None, 10, 512)      0           decoder_layer6_layernorm2[0][0]  \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer6_layernorm3 (Laye (None, 10, 512)      10240       decoder_layer6_residual3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "shared_weights_5 (SharedWeights (None, 10, 551)      0           decoder_layer6_layernorm3[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 11,611,648\n",
      "Trainable params: 11,611,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# def loss(y_true, y_pred):\n",
    "#    return K.categorical_crossentropy(y_true[:,-1:,:], y_pred[:,-1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRScheduler:\n",
    "    def __init__(self, d_model, warmup_steps):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.epoch = 1\n",
    "\n",
    "    def lr(self, epoch):\n",
    "        lr = self.d_model**-.5 * min(self.epoch**-.5, epoch*(self.warmup_steps**-1.5))\n",
    "        self.epoch += 1\n",
    "        return lr\n",
    "lr_scheduler = LRScheduler(d_model, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "# callbacks.append(LearningRateScheduler(lr_scheduler.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "model.compile(loss=loss, optimizer=adam(lr=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# old_lr = K.get_value(model.optimizer.lr)\n",
    "# K.set_value(model.optimizer.lr, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "83/83 [==============================] - 31s 373ms/step - loss: 6.1677\n",
      "Epoch 2/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 5.8673\n",
      "Epoch 3/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.6662\n",
      "Epoch 4/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 5.5196\n",
      "Epoch 5/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 5.4028\n",
      "Epoch 6/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 5.3272\n",
      "Epoch 7/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.2618\n",
      "Epoch 8/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.1847\n",
      "Epoch 9/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.1433\n",
      "Epoch 10/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.0959\n",
      "Epoch 11/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 5.0487\n",
      "Epoch 12/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 5.0119\n",
      "Epoch 13/1000\n",
      "83/83 [==============================] - 13s 160ms/step - loss: 4.9695\n",
      "Epoch 14/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.9409\n",
      "Epoch 15/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.8644\n",
      "Epoch 16/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.9381\n",
      "Epoch 17/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.7523\n",
      "Epoch 18/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.7778\n",
      "Epoch 19/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.8525\n",
      "Epoch 20/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.6316\n",
      "Epoch 21/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.6541\n",
      "Epoch 22/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.7223\n",
      "Epoch 23/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.6038\n",
      "Epoch 24/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.6639\n",
      "Epoch 25/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.6175\n",
      "Epoch 26/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.5357\n",
      "Epoch 27/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.6245\n",
      "Epoch 28/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.5503\n",
      "Epoch 29/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4891\n",
      "Epoch 30/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.5050\n",
      "Epoch 31/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.5102\n",
      "Epoch 32/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4990\n",
      "Epoch 33/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4923\n",
      "Epoch 34/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.5345\n",
      "Epoch 35/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3690\n",
      "Epoch 36/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4526\n",
      "Epoch 37/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4524\n",
      "Epoch 38/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4053\n",
      "Epoch 39/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3895\n",
      "Epoch 40/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.5238\n",
      "Epoch 41/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2094\n",
      "Epoch 42/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.4143\n",
      "Epoch 43/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2779\n",
      "Epoch 44/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4136\n",
      "Epoch 45/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2920\n",
      "Epoch 46/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3541\n",
      "Epoch 47/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3828\n",
      "Epoch 48/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3871\n",
      "Epoch 49/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2390\n",
      "Epoch 50/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2908\n",
      "Epoch 51/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2624\n",
      "Epoch 52/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3439\n",
      "Epoch 53/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3347\n",
      "Epoch 54/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3655\n",
      "Epoch 55/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0886\n",
      "Epoch 56/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2888\n",
      "Epoch 57/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2352\n",
      "Epoch 58/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3509\n",
      "Epoch 59/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2379\n",
      "Epoch 60/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3240\n",
      "Epoch 61/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1985\n",
      "Epoch 62/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4506\n",
      "Epoch 63/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.0884\n",
      "Epoch 64/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4506\n",
      "Epoch 65/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0927\n",
      "Epoch 66/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2018\n",
      "Epoch 67/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2463\n",
      "Epoch 68/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2406\n",
      "Epoch 69/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3683\n",
      "Epoch 70/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2238\n",
      "Epoch 71/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4016\n",
      "Epoch 72/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0137\n",
      "Epoch 73/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2813\n",
      "Epoch 74/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3393\n",
      "Epoch 75/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2311\n",
      "Epoch 76/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4127\n",
      "Epoch 77/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0934\n",
      "Epoch 78/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2918\n",
      "Epoch 79/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0894\n",
      "Epoch 80/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2935\n",
      "Epoch 81/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3435\n",
      "Epoch 82/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1755\n",
      "Epoch 83/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2911\n",
      "Epoch 84/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2112\n",
      "Epoch 85/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2978\n",
      "Epoch 86/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2425\n",
      "Epoch 87/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2352\n",
      "Epoch 88/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2159\n",
      "Epoch 89/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2880\n",
      "Epoch 90/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4031\n",
      "Epoch 91/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1715\n",
      "Epoch 92/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0801\n",
      "Epoch 93/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2768\n",
      "Epoch 94/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2480\n",
      "Epoch 95/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3592\n",
      "Epoch 96/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3641\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 155ms/step - loss: 3.9942\n",
      "Epoch 98/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2602\n",
      "Epoch 99/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.4024\n",
      "Epoch 100/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1989\n",
      "Epoch 101/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3688\n",
      "Epoch 102/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1511\n",
      "Epoch 103/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1294\n",
      "Epoch 104/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3938\n",
      "Epoch 105/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1227\n",
      "Epoch 106/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2554\n",
      "Epoch 107/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3595\n",
      "Epoch 108/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0706\n",
      "Epoch 109/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.5764\n",
      "Epoch 110/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1305\n",
      "Epoch 111/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2177\n",
      "Epoch 112/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3473\n",
      "Epoch 113/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0442\n",
      "Epoch 114/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3725\n",
      "Epoch 115/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2368\n",
      "Epoch 116/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2264\n",
      "Epoch 117/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.4218\n",
      "Epoch 118/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0895\n",
      "Epoch 119/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2254\n",
      "Epoch 120/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2378\n",
      "Epoch 121/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4417\n",
      "Epoch 122/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1035\n",
      "Epoch 123/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3073\n",
      "Epoch 124/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3336\n",
      "Epoch 125/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1365\n",
      "Epoch 126/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2699\n",
      "Epoch 127/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3396\n",
      "Epoch 128/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3424\n",
      "Epoch 129/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1642\n",
      "Epoch 130/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1855\n",
      "Epoch 131/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2222\n",
      "Epoch 132/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3764\n",
      "Epoch 133/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3189\n",
      "Epoch 134/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1837\n",
      "Epoch 135/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2858\n",
      "Epoch 136/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1613\n",
      "Epoch 137/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3026\n",
      "Epoch 138/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3050\n",
      "Epoch 139/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2108\n",
      "Epoch 140/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0977\n",
      "Epoch 141/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4571\n",
      "Epoch 142/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0992\n",
      "Epoch 143/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2682\n",
      "Epoch 144/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2863\n",
      "Epoch 145/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2756\n",
      "Epoch 146/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1248\n",
      "Epoch 147/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3417\n",
      "Epoch 148/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2881\n",
      "Epoch 149/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3452\n",
      "Epoch 150/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2401\n",
      "Epoch 151/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1431\n",
      "Epoch 152/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4481\n",
      "Epoch 153/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1409\n",
      "Epoch 154/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3410\n",
      "Epoch 155/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2525\n",
      "Epoch 156/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2590\n",
      "Epoch 157/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2025\n",
      "Epoch 158/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2214\n",
      "Epoch 159/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.4012\n",
      "Epoch 160/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2463\n",
      "Epoch 161/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1918\n",
      "Epoch 162/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2823\n",
      "Epoch 163/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1110\n",
      "Epoch 164/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4385\n",
      "Epoch 165/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2002\n",
      "Epoch 166/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3146\n",
      "Epoch 167/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2529\n",
      "Epoch 168/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2752\n",
      "Epoch 169/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2015\n",
      "Epoch 170/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3303\n",
      "Epoch 171/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2127\n",
      "Epoch 172/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1320\n",
      "Epoch 173/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2282\n",
      "Epoch 174/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2556\n",
      "Epoch 175/1000\n",
      "83/83 [==============================] - 13s 160ms/step - loss: 4.4499\n",
      "Epoch 176/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2699\n",
      "Epoch 177/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2184\n",
      "Epoch 178/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2474\n",
      "Epoch 179/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2564\n",
      "Epoch 180/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1656\n",
      "Epoch 181/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2240\n",
      "Epoch 182/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4149\n",
      "Epoch 183/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2777\n",
      "Epoch 184/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2110\n",
      "Epoch 185/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2632\n",
      "Epoch 186/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2216\n",
      "Epoch 187/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2672\n",
      "Epoch 188/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2158\n",
      "Epoch 189/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2555\n",
      "Epoch 190/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3270\n",
      "Epoch 191/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3007\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2119\n",
      "Epoch 193/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2916\n",
      "Epoch 194/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2718\n",
      "Epoch 195/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2281\n",
      "Epoch 196/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0842\n",
      "Epoch 197/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4146\n",
      "Epoch 198/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1248\n",
      "Epoch 199/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2627\n",
      "Epoch 200/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.4229\n",
      "Epoch 201/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2359\n",
      "Epoch 202/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2389\n",
      "Epoch 203/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2609\n",
      "Epoch 204/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2451\n",
      "Epoch 205/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2450\n",
      "Epoch 206/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2725\n",
      "Epoch 207/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2492\n",
      "Epoch 208/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1863\n",
      "Epoch 209/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3198\n",
      "Epoch 210/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2798\n",
      "Epoch 211/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2503\n",
      "Epoch 212/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2404\n",
      "Epoch 213/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2164\n",
      "Epoch 214/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2943\n",
      "Epoch 215/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2522\n",
      "Epoch 216/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2642\n",
      "Epoch 217/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2521\n",
      "Epoch 218/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2559\n",
      "Epoch 219/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2588\n",
      "Epoch 220/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2523\n",
      "Epoch 221/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2504\n",
      "Epoch 222/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2601\n",
      "Epoch 223/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2590\n",
      "Epoch 224/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2443\n",
      "Epoch 225/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2784\n",
      "Epoch 226/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2356\n",
      "Epoch 227/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2865\n",
      "Epoch 228/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2238\n",
      "Epoch 229/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3129\n",
      "Epoch 230/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1764\n",
      "Epoch 231/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3432\n",
      "Epoch 232/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1934\n",
      "Epoch 233/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2018\n",
      "Epoch 234/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2559\n",
      "Epoch 235/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2956\n",
      "Epoch 236/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2518\n",
      "Epoch 237/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2561\n",
      "Epoch 238/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2558\n",
      "Epoch 239/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2462\n",
      "Epoch 240/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2541\n",
      "Epoch 241/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2190\n",
      "Epoch 242/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3698\n",
      "Epoch 243/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1818\n",
      "Epoch 244/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1918\n",
      "Epoch 245/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2541\n",
      "Epoch 246/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3218\n",
      "Epoch 247/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2329\n",
      "Epoch 248/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2424\n",
      "Epoch 249/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2569\n",
      "Epoch 250/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2799\n",
      "Epoch 251/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3634\n",
      "Epoch 252/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0987\n",
      "Epoch 253/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2534\n",
      "Epoch 254/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2480\n",
      "Epoch 255/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3189\n",
      "Epoch 256/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1887\n",
      "Epoch 257/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2305\n",
      "Epoch 258/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2184\n",
      "Epoch 259/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2764\n",
      "Epoch 260/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2687\n",
      "Epoch 261/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2114\n",
      "Epoch 262/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3656\n",
      "Epoch 263/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2235\n",
      "Epoch 264/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1978\n",
      "Epoch 265/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4173\n",
      "Epoch 266/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1548\n",
      "Epoch 267/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2583\n",
      "Epoch 268/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2685\n",
      "Epoch 269/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1734\n",
      "Epoch 270/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3601\n",
      "Epoch 271/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1080\n",
      "Epoch 272/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3976\n",
      "Epoch 273/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2102\n",
      "Epoch 274/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1035\n",
      "Epoch 275/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3022\n",
      "Epoch 276/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2336\n",
      "Epoch 277/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3557\n",
      "Epoch 278/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2518\n",
      "Epoch 279/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3177\n",
      "Epoch 280/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1018\n",
      "Epoch 281/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4179\n",
      "Epoch 282/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0017\n",
      "Epoch 283/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2495\n",
      "Epoch 284/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3327\n",
      "Epoch 285/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4617\n",
      "Epoch 286/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 3.9756\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4251\n",
      "Epoch 288/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1203\n",
      "Epoch 289/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3348\n",
      "Epoch 290/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1197\n",
      "Epoch 291/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2273\n",
      "Epoch 292/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.5381\n",
      "Epoch 293/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0232\n",
      "Epoch 294/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3440\n",
      "Epoch 295/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2758\n",
      "Epoch 296/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2068\n",
      "Epoch 297/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3359\n",
      "Epoch 298/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1869\n",
      "Epoch 299/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2919\n",
      "Epoch 300/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2210\n",
      "Epoch 301/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0798\n",
      "Epoch 302/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4316\n",
      "Epoch 303/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2828\n",
      "Epoch 304/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 3.9993\n",
      "Epoch 305/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2769\n",
      "Epoch 306/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3603\n",
      "Epoch 307/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2424\n",
      "Epoch 308/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1627\n",
      "Epoch 309/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2711\n",
      "Epoch 310/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.5077\n",
      "Epoch 311/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0156\n",
      "Epoch 312/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3638\n",
      "Epoch 313/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1687\n",
      "Epoch 314/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3242\n",
      "Epoch 315/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3336\n",
      "Epoch 316/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1508\n",
      "Epoch 317/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3471\n",
      "Epoch 318/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 3.9696\n",
      "Epoch 319/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.4415\n",
      "Epoch 320/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1586\n",
      "Epoch 321/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2525\n",
      "Epoch 322/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1935\n",
      "Epoch 323/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1630\n",
      "Epoch 324/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4311\n",
      "Epoch 325/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1790\n",
      "Epoch 326/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1711\n",
      "Epoch 327/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3448\n",
      "Epoch 328/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4123\n",
      "Epoch 329/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0301\n",
      "Epoch 330/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3216\n",
      "Epoch 331/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3261\n",
      "Epoch 332/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2392\n",
      "Epoch 333/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2831\n",
      "Epoch 334/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1754\n",
      "Epoch 335/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0390\n",
      "Epoch 336/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4212\n",
      "Epoch 337/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2683\n",
      "Epoch 338/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2090\n",
      "Epoch 339/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2031\n",
      "Epoch 340/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3161\n",
      "Epoch 341/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3042\n",
      "Epoch 342/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1033\n",
      "Epoch 343/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.4024\n",
      "Epoch 344/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2404\n",
      "Epoch 345/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2137\n",
      "Epoch 346/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0699\n",
      "Epoch 347/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.5142\n",
      "Epoch 348/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0351\n",
      "Epoch 349/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4868\n",
      "Epoch 350/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1080\n",
      "Epoch 351/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2500\n",
      "Epoch 352/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3161\n",
      "Epoch 353/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1662\n",
      "Epoch 354/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1424\n",
      "Epoch 355/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3618\n",
      "Epoch 356/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3151\n",
      "Epoch 357/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1641\n",
      "Epoch 358/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2822\n",
      "Epoch 359/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2221\n",
      "Epoch 360/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1328\n",
      "Epoch 361/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4114\n",
      "Epoch 362/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.1532\n",
      "Epoch 363/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3148\n",
      "Epoch 364/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3216\n",
      "Epoch 365/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2368\n",
      "Epoch 366/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 3.9966\n",
      "Epoch 367/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3687\n",
      "Epoch 368/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2227\n",
      "Epoch 369/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3347\n",
      "Epoch 370/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3048\n",
      "Epoch 371/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1291\n",
      "Epoch 372/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1832\n",
      "Epoch 373/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3676\n",
      "Epoch 374/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1627\n",
      "Epoch 375/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2654\n",
      "Epoch 376/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2412\n",
      "Epoch 377/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2863\n",
      "Epoch 378/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2474\n",
      "Epoch 379/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2683\n",
      "Epoch 380/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2603\n",
      "Epoch 381/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0876\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3498\n",
      "Epoch 383/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1534\n",
      "Epoch 384/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3944\n",
      "Epoch 385/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2010\n",
      "Epoch 386/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2862\n",
      "Epoch 387/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2597\n",
      "Epoch 388/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2519\n",
      "Epoch 389/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2110\n",
      "Epoch 390/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2593\n",
      "Epoch 391/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1078\n",
      "Epoch 392/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3673\n",
      "Epoch 393/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2549\n",
      "Epoch 394/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2111\n",
      "Epoch 395/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2632\n",
      "Epoch 396/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2418\n",
      "Epoch 397/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0752\n",
      "Epoch 398/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4205\n",
      "Epoch 399/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1036\n",
      "Epoch 400/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3721\n",
      "Epoch 401/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1657\n",
      "Epoch 402/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3168\n",
      "Epoch 403/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2726\n",
      "Epoch 404/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1052\n",
      "Epoch 405/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3260\n",
      "Epoch 406/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2707\n",
      "Epoch 407/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2827\n",
      "Epoch 408/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2493\n",
      "Epoch 409/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1722\n",
      "Epoch 410/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1991\n",
      "Epoch 411/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3205\n",
      "Epoch 412/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2270\n",
      "Epoch 413/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2836\n",
      "Epoch 414/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2337\n",
      "Epoch 415/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.2320\n",
      "Epoch 416/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2423\n",
      "Epoch 417/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2609\n",
      "Epoch 418/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1966\n",
      "Epoch 419/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2442\n",
      "Epoch 420/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2748\n",
      "Epoch 421/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2439\n",
      "Epoch 422/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2156\n",
      "Epoch 423/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2690\n",
      "Epoch 424/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2492\n",
      "Epoch 425/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2429\n",
      "Epoch 426/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2508\n",
      "Epoch 427/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2675\n",
      "Epoch 428/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1912\n",
      "Epoch 429/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2644\n",
      "Epoch 430/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2691\n",
      "Epoch 431/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2198\n",
      "Epoch 432/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2586\n",
      "Epoch 433/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2333\n",
      "Epoch 434/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2381\n",
      "Epoch 435/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2368\n",
      "Epoch 436/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2438\n",
      "Epoch 437/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2386\n",
      "Epoch 438/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2397\n",
      "Epoch 439/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2467\n",
      "Epoch 440/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2417\n",
      "Epoch 441/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2317\n",
      "Epoch 442/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2480\n",
      "Epoch 443/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2450\n",
      "Epoch 444/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2414\n",
      "Epoch 445/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2490\n",
      "Epoch 446/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2357\n",
      "Epoch 447/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2659\n",
      "Epoch 448/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2480\n",
      "Epoch 449/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2555\n",
      "Epoch 450/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2110\n",
      "Epoch 451/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2746\n",
      "Epoch 452/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2076\n",
      "Epoch 453/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2147\n",
      "Epoch 454/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2776\n",
      "Epoch 455/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2379\n",
      "Epoch 456/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1888\n",
      "Epoch 457/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2909\n",
      "Epoch 458/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2566\n",
      "Epoch 459/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3284\n",
      "Epoch 460/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1303\n",
      "Epoch 461/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2487\n",
      "Epoch 462/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1915\n",
      "Epoch 463/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3151\n",
      "Epoch 464/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1924\n",
      "Epoch 465/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2697\n",
      "Epoch 466/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3768\n",
      "Epoch 467/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0990\n",
      "Epoch 468/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2425\n",
      "Epoch 469/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3240\n",
      "Epoch 470/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1735\n",
      "Epoch 471/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2587\n",
      "Epoch 472/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2958\n",
      "Epoch 473/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1297\n",
      "Epoch 474/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3239\n",
      "Epoch 475/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2692\n",
      "Epoch 476/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3062\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2580\n",
      "Epoch 478/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1181\n",
      "Epoch 479/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3422\n",
      "Epoch 480/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.0932\n",
      "Epoch 481/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.3365\n",
      "Epoch 482/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1630\n",
      "Epoch 483/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1989\n",
      "Epoch 484/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.3123\n",
      "Epoch 485/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1925\n",
      "Epoch 486/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1746\n",
      "Epoch 487/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2633\n",
      "Epoch 488/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4220\n",
      "Epoch 489/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1091\n",
      "Epoch 490/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2391\n",
      "Epoch 491/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2482\n",
      "Epoch 492/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3767\n",
      "Epoch 493/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0687\n",
      "Epoch 494/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.4135\n",
      "Epoch 495/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1194\n",
      "Epoch 496/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3494\n",
      "Epoch 497/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.0899\n",
      "Epoch 498/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3214\n",
      "Epoch 499/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2423\n",
      "Epoch 500/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2277\n",
      "Epoch 501/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1867\n",
      "Epoch 502/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3699\n",
      "Epoch 503/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1634\n",
      "Epoch 504/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.4325\n",
      "Epoch 505/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0135\n",
      "Epoch 506/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2782\n",
      "Epoch 507/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2543\n",
      "Epoch 508/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2315\n",
      "Epoch 509/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4094\n",
      "Epoch 510/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.0194\n",
      "Epoch 511/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3216\n",
      "Epoch 512/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2446\n",
      "Epoch 513/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2055\n",
      "Epoch 514/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1468\n",
      "Epoch 515/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4239\n",
      "Epoch 516/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2543\n",
      "Epoch 517/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1294\n",
      "Epoch 518/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2507\n",
      "Epoch 519/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2653\n",
      "Epoch 520/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2847\n",
      "Epoch 521/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1369\n",
      "Epoch 522/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3152\n",
      "Epoch 523/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1716\n",
      "Epoch 524/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1906\n",
      "Epoch 525/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3384\n",
      "Epoch 526/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1797\n",
      "Epoch 527/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1589\n",
      "Epoch 528/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2708\n",
      "Epoch 529/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3307\n",
      "Epoch 530/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2156\n",
      "Epoch 531/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2742\n",
      "Epoch 532/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2406\n",
      "Epoch 533/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2722\n",
      "Epoch 534/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1041\n",
      "Epoch 535/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.4131\n",
      "Epoch 536/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.2346\n",
      "Epoch 537/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1709\n",
      "Epoch 538/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2901\n",
      "Epoch 539/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2292\n",
      "Epoch 540/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1833\n",
      "Epoch 541/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3348\n",
      "Epoch 542/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2427\n",
      "Epoch 543/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3295\n",
      "Epoch 544/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 3.9897\n",
      "Epoch 545/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3407\n",
      "Epoch 546/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2508\n",
      "Epoch 547/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2106\n",
      "Epoch 548/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3123\n",
      "Epoch 549/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1618\n",
      "Epoch 550/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3509\n",
      "Epoch 551/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1996\n",
      "Epoch 552/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2233\n",
      "Epoch 553/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1690\n",
      "Epoch 554/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3336\n",
      "Epoch 555/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0577\n",
      "Epoch 556/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3718\n",
      "Epoch 557/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2305\n",
      "Epoch 558/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0852\n",
      "Epoch 559/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4433\n",
      "Epoch 560/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3189\n",
      "Epoch 561/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2705\n",
      "Epoch 562/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0412\n",
      "Epoch 563/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2794\n",
      "Epoch 564/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3661\n",
      "Epoch 565/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1253\n",
      "Epoch 566/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2279\n",
      "Epoch 567/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2860\n",
      "Epoch 568/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2894\n",
      "Epoch 569/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2591\n",
      "Epoch 570/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3051\n",
      "Epoch 571/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.0004\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3314\n",
      "Epoch 573/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.3353\n",
      "Epoch 574/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0708\n",
      "Epoch 575/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2803\n",
      "Epoch 576/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2928\n",
      "Epoch 577/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2818\n",
      "Epoch 578/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0417\n",
      "Epoch 579/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3572\n",
      "Epoch 580/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1611\n",
      "Epoch 581/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2172\n",
      "Epoch 582/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3853\n",
      "Epoch 583/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0386\n",
      "Epoch 584/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3859\n",
      "Epoch 585/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2583\n",
      "Epoch 586/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3013\n",
      "Epoch 587/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1899\n",
      "Epoch 588/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3226\n",
      "Epoch 589/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0947\n",
      "Epoch 590/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3915\n",
      "Epoch 591/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0195\n",
      "Epoch 592/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3645\n",
      "Epoch 593/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2126\n",
      "Epoch 594/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3385\n",
      "Epoch 595/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1344\n",
      "Epoch 596/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3675\n",
      "Epoch 597/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2131\n",
      "Epoch 598/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2612\n",
      "Epoch 599/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2436\n",
      "Epoch 600/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1628\n",
      "Epoch 601/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3037\n",
      "Epoch 602/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2681\n",
      "Epoch 603/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0918\n",
      "Epoch 604/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2610\n",
      "Epoch 605/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1762\n",
      "Epoch 606/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3556\n",
      "Epoch 607/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1608\n",
      "Epoch 608/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1539\n",
      "Epoch 609/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.4543\n",
      "Epoch 610/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1635\n",
      "Epoch 611/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1733\n",
      "Epoch 612/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3749\n",
      "Epoch 613/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1969\n",
      "Epoch 614/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.0464\n",
      "Epoch 615/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2732\n",
      "Epoch 616/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3605\n",
      "Epoch 617/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2490\n",
      "Epoch 618/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2299\n",
      "Epoch 619/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2703\n",
      "Epoch 620/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0949\n",
      "Epoch 621/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3181\n",
      "Epoch 622/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2844\n",
      "Epoch 623/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2810\n",
      "Epoch 624/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2084\n",
      "Epoch 625/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2359\n",
      "Epoch 626/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2503\n",
      "Epoch 627/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2399\n",
      "Epoch 628/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.0936\n",
      "Epoch 629/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3658\n",
      "Epoch 630/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1648\n",
      "Epoch 631/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3260\n",
      "Epoch 632/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2448\n",
      "Epoch 633/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1719\n",
      "Epoch 634/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3049\n",
      "Epoch 635/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1728\n",
      "Epoch 636/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2610\n",
      "Epoch 637/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2737\n",
      "Epoch 638/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2006\n",
      "Epoch 639/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2555\n",
      "Epoch 640/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2329\n",
      "Epoch 641/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2469\n",
      "Epoch 642/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2916\n",
      "Epoch 643/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1960\n",
      "Epoch 644/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2771\n",
      "Epoch 645/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0906\n",
      "Epoch 646/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3623\n",
      "Epoch 647/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2326\n",
      "Epoch 648/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2061\n",
      "Epoch 649/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2645\n",
      "Epoch 650/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2697\n",
      "Epoch 651/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2158\n",
      "Epoch 652/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2482\n",
      "Epoch 653/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2334\n",
      "Epoch 654/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2257\n",
      "Epoch 655/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2479\n",
      "Epoch 656/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2345\n",
      "Epoch 657/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2455\n",
      "Epoch 658/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2431\n",
      "Epoch 659/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2208\n",
      "Epoch 660/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2429\n",
      "Epoch 661/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2419\n",
      "Epoch 662/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2313\n",
      "Epoch 663/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2313\n",
      "Epoch 664/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2442\n",
      "Epoch 665/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2366\n",
      "Epoch 666/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2349\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2385\n",
      "Epoch 668/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2458\n",
      "Epoch 669/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2499\n",
      "Epoch 670/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2267\n",
      "Epoch 671/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2065\n",
      "Epoch 672/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2969\n",
      "Epoch 673/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1871\n",
      "Epoch 674/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2508\n",
      "Epoch 675/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2493\n",
      "Epoch 676/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2372\n",
      "Epoch 677/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2355\n",
      "Epoch 678/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2255\n",
      "Epoch 679/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2429\n",
      "Epoch 680/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2289\n",
      "Epoch 681/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2155\n",
      "Epoch 682/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2553\n",
      "Epoch 683/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2494\n",
      "Epoch 684/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2569\n",
      "Epoch 685/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2359\n",
      "Epoch 686/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2077\n",
      "Epoch 687/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2162\n",
      "Epoch 688/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2621\n",
      "Epoch 689/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2393\n",
      "Epoch 690/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2321\n",
      "Epoch 691/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2588\n",
      "Epoch 692/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1780\n",
      "Epoch 693/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2795\n",
      "Epoch 694/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3113\n",
      "Epoch 695/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1004\n",
      "Epoch 696/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2762\n",
      "Epoch 697/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2740\n",
      "Epoch 698/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2182\n",
      "Epoch 699/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2260\n",
      "Epoch 700/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2148\n",
      "Epoch 701/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3779\n",
      "Epoch 702/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0960\n",
      "Epoch 703/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3554\n",
      "Epoch 704/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1087\n",
      "Epoch 705/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2811\n",
      "Epoch 706/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1913\n",
      "Epoch 707/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4054\n",
      "Epoch 708/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1547\n",
      "Epoch 709/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1444\n",
      "Epoch 710/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.4203\n",
      "Epoch 711/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0614\n",
      "Epoch 712/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4243\n",
      "Epoch 713/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0374\n",
      "Epoch 714/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2659\n",
      "Epoch 715/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3142\n",
      "Epoch 716/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1832\n",
      "Epoch 717/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2853\n",
      "Epoch 718/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3170\n",
      "Epoch 719/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1510\n",
      "Epoch 720/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2113\n",
      "Epoch 721/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2126\n",
      "Epoch 722/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3119\n",
      "Epoch 723/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2431\n",
      "Epoch 724/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1871\n",
      "Epoch 725/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3680\n",
      "Epoch 726/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1120\n",
      "Epoch 727/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2935\n",
      "Epoch 728/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1942\n",
      "Epoch 729/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1228\n",
      "Epoch 730/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3776\n",
      "Epoch 731/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1286\n",
      "Epoch 732/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4434\n",
      "Epoch 733/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1459\n",
      "Epoch 734/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1817\n",
      "Epoch 735/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2477\n",
      "Epoch 736/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3336\n",
      "Epoch 737/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1316\n",
      "Epoch 738/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3008\n",
      "Epoch 739/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2739\n",
      "Epoch 740/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0457\n",
      "Epoch 741/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.4352\n",
      "Epoch 742/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1444\n",
      "Epoch 743/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.4400\n",
      "Epoch 744/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 3.9481\n",
      "Epoch 745/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.2910\n",
      "Epoch 746/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2824\n",
      "Epoch 747/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1700\n",
      "Epoch 748/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2469\n",
      "Epoch 749/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3522\n",
      "Epoch 750/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2568\n",
      "Epoch 751/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3607\n",
      "Epoch 752/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0882\n",
      "Epoch 753/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2741\n",
      "Epoch 754/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3603\n",
      "Epoch 755/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.0031\n",
      "Epoch 756/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4546\n",
      "Epoch 757/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0787\n",
      "Epoch 758/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2279\n",
      "Epoch 759/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1561\n",
      "Epoch 760/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3208\n",
      "Epoch 761/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1594\n",
      "Epoch 762/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3508\n",
      "Epoch 763/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2670\n",
      "Epoch 764/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3202\n",
      "Epoch 765/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2152\n",
      "Epoch 766/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0144\n",
      "Epoch 767/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.5115\n",
      "Epoch 768/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 3.9304\n",
      "Epoch 769/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2439\n",
      "Epoch 770/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.4499\n",
      "Epoch 771/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1880\n",
      "Epoch 772/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2040\n",
      "Epoch 773/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3007\n",
      "Epoch 774/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2442\n",
      "Epoch 775/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0984\n",
      "Epoch 776/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2598\n",
      "Epoch 777/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3835\n",
      "Epoch 778/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1290\n",
      "Epoch 779/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3156\n",
      "Epoch 780/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1755\n",
      "Epoch 781/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.0880\n",
      "Epoch 782/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3069\n",
      "Epoch 783/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3883\n",
      "Epoch 784/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 3.9527\n",
      "Epoch 785/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3233\n",
      "Epoch 786/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4796\n",
      "Epoch 787/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 3.9858\n",
      "Epoch 788/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3594\n",
      "Epoch 789/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2980\n",
      "Epoch 790/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1401\n",
      "Epoch 791/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2199\n",
      "Epoch 792/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2445\n",
      "Epoch 793/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3667\n",
      "Epoch 794/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0465\n",
      "Epoch 795/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3623\n",
      "Epoch 796/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2349\n",
      "Epoch 797/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2812\n",
      "Epoch 798/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2216\n",
      "Epoch 799/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1400\n",
      "Epoch 800/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3265\n",
      "Epoch 801/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1366\n",
      "Epoch 802/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2315\n",
      "Epoch 803/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2484\n",
      "Epoch 804/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0772\n",
      "Epoch 805/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4515\n",
      "Epoch 806/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1692\n",
      "Epoch 807/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3685\n",
      "Epoch 808/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2364\n",
      "Epoch 809/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2214\n",
      "Epoch 810/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2305\n",
      "Epoch 811/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0002\n",
      "Epoch 812/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2604\n",
      "Epoch 813/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2920\n",
      "Epoch 814/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3996\n",
      "Epoch 815/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2092\n",
      "Epoch 816/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1969\n",
      "Epoch 817/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2249\n",
      "Epoch 818/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2854\n",
      "Epoch 819/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.0918\n",
      "Epoch 820/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3889\n",
      "Epoch 821/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1305\n",
      "Epoch 822/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3566\n",
      "Epoch 823/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3030\n",
      "Epoch 824/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1929\n",
      "Epoch 825/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.1145\n",
      "Epoch 826/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2570\n",
      "Epoch 827/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3123\n",
      "Epoch 828/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2480\n",
      "Epoch 829/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2445\n",
      "Epoch 830/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1254\n",
      "Epoch 831/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3719\n",
      "Epoch 832/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.0962\n",
      "Epoch 833/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3141\n",
      "Epoch 834/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1569\n",
      "Epoch 835/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3578\n",
      "Epoch 836/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0500\n",
      "Epoch 837/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2656\n",
      "Epoch 838/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3662\n",
      "Epoch 839/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2026\n",
      "Epoch 840/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2856\n",
      "Epoch 841/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2407\n",
      "Epoch 842/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2206\n",
      "Epoch 843/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1863\n",
      "Epoch 844/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2722\n",
      "Epoch 845/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3086\n",
      "Epoch 846/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2018\n",
      "Epoch 847/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2027\n",
      "Epoch 848/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1555\n",
      "Epoch 849/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3205\n",
      "Epoch 850/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2442\n",
      "Epoch 851/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2262\n",
      "Epoch 852/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1445\n",
      "Epoch 853/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3627\n",
      "Epoch 854/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2157\n",
      "Epoch 855/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.0996\n",
      "Epoch 856/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3567\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2370\n",
      "Epoch 858/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2387\n",
      "Epoch 859/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2662\n",
      "Epoch 860/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1878\n",
      "Epoch 861/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2395\n",
      "Epoch 862/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1972\n",
      "Epoch 863/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2763\n",
      "Epoch 864/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2200\n",
      "Epoch 865/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2712\n",
      "Epoch 866/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2095\n",
      "Epoch 867/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2809\n",
      "Epoch 868/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1942\n",
      "Epoch 869/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2373\n",
      "Epoch 870/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2383\n",
      "Epoch 871/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2350\n",
      "Epoch 872/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2403\n",
      "Epoch 873/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2337\n",
      "Epoch 874/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1585\n",
      "Epoch 875/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3402\n",
      "Epoch 876/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2305\n",
      "Epoch 877/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2152\n",
      "Epoch 878/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2166\n",
      "Epoch 879/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2503\n",
      "Epoch 880/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2333\n",
      "Epoch 881/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2354\n",
      "Epoch 882/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2349\n",
      "Epoch 883/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2338\n",
      "Epoch 884/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2273\n",
      "Epoch 885/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2353\n",
      "Epoch 886/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2473\n",
      "Epoch 887/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2294\n",
      "Epoch 888/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2369\n",
      "Epoch 889/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2350\n",
      "Epoch 890/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2343\n",
      "Epoch 891/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2343\n",
      "Epoch 892/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2495\n",
      "Epoch 893/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2158\n",
      "Epoch 894/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2376\n",
      "Epoch 895/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2332\n",
      "Epoch 896/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2922\n",
      "Epoch 897/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.1534\n",
      "Epoch 898/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2147\n",
      "Epoch 899/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.3474\n",
      "Epoch 900/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1343\n",
      "Epoch 901/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2205\n",
      "Epoch 902/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2642\n",
      "Epoch 903/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2497\n",
      "Epoch 904/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2368\n",
      "Epoch 905/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3445\n",
      "Epoch 906/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1210\n",
      "Epoch 907/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3283\n",
      "Epoch 908/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2769\n",
      "Epoch 909/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2013\n",
      "Epoch 910/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1288\n",
      "Epoch 911/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2492\n",
      "Epoch 912/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.2529\n",
      "Epoch 913/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2191\n",
      "Epoch 914/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3714\n",
      "Epoch 915/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0471\n",
      "Epoch 916/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2495\n",
      "Epoch 917/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.3266\n",
      "Epoch 918/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2022\n",
      "Epoch 919/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3065\n",
      "Epoch 920/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1612\n",
      "Epoch 921/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2816\n",
      "Epoch 922/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1698\n",
      "Epoch 923/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1769\n",
      "Epoch 924/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2045\n",
      "Epoch 925/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.4148\n",
      "Epoch 926/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1021\n",
      "Epoch 927/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.4920\n",
      "Epoch 928/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 3.9957\n",
      "Epoch 929/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2208\n",
      "Epoch 930/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2579\n",
      "Epoch 931/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2698\n",
      "Epoch 932/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2031\n",
      "Epoch 933/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1966\n",
      "Epoch 934/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2570\n",
      "Epoch 935/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3932\n",
      "Epoch 936/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1232\n",
      "Epoch 937/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2340\n",
      "Epoch 938/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2307\n",
      "Epoch 939/1000\n",
      "83/83 [==============================] - 13s 152ms/step - loss: 4.2380\n",
      "Epoch 940/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1975\n",
      "Epoch 941/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2705\n",
      "Epoch 942/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.1498\n",
      "Epoch 943/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3347\n",
      "Epoch 944/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2319\n",
      "Epoch 945/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3424\n",
      "Epoch 946/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 3.9952\n",
      "Epoch 947/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2723\n",
      "Epoch 948/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2976\n",
      "Epoch 949/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.2325\n",
      "Epoch 950/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2677\n",
      "Epoch 951/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4023\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 13s 157ms/step - loss: 3.9397\n",
      "Epoch 953/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2589\n",
      "Epoch 954/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4080\n",
      "Epoch 955/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1978\n",
      "Epoch 956/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2281\n",
      "Epoch 957/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2783\n",
      "Epoch 958/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.1752\n",
      "Epoch 959/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2613\n",
      "Epoch 960/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0888\n",
      "Epoch 961/1000\n",
      "83/83 [==============================] - 13s 159ms/step - loss: 4.3022\n",
      "Epoch 962/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1627\n",
      "Epoch 963/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.3921\n",
      "Epoch 964/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3136\n",
      "Epoch 965/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1202\n",
      "Epoch 966/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2255\n",
      "Epoch 967/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2337\n",
      "Epoch 968/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1432\n",
      "Epoch 969/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.4461\n",
      "Epoch 970/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0226\n",
      "Epoch 971/1000\n",
      "83/83 [==============================] - 13s 153ms/step - loss: 4.3827\n",
      "Epoch 972/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.0754\n",
      "Epoch 973/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3082\n",
      "Epoch 974/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1597\n",
      "Epoch 975/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3724\n",
      "Epoch 976/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1240\n",
      "Epoch 977/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1996\n",
      "Epoch 978/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2909\n",
      "Epoch 979/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3899\n",
      "Epoch 980/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2380\n",
      "Epoch 981/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2102\n",
      "Epoch 982/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2145\n",
      "Epoch 983/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1698\n",
      "Epoch 984/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2122\n",
      "Epoch 985/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2944\n",
      "Epoch 986/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.2352\n",
      "Epoch 987/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.3843\n",
      "Epoch 988/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.0262\n",
      "Epoch 989/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2872\n",
      "Epoch 990/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1565\n",
      "Epoch 991/1000\n",
      "83/83 [==============================] - 13s 158ms/step - loss: 4.2689\n",
      "Epoch 992/1000\n",
      "83/83 [==============================] - 13s 154ms/step - loss: 4.1969\n",
      "Epoch 993/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.4073\n",
      "Epoch 994/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.1353\n",
      "Epoch 995/1000\n",
      "83/83 [==============================] - 13s 157ms/step - loss: 4.1589\n",
      "Epoch 996/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3042\n",
      "Epoch 997/1000\n",
      "83/83 [==============================] - 13s 156ms/step - loss: 4.2517\n",
      "Epoch 998/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.3193\n",
      "Epoch 999/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.0414\n",
      "Epoch 1000/1000\n",
      "83/83 [==============================] - 13s 155ms/step - loss: 4.2490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9b46324a8>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "model.fit_generator(\n",
    "    train_gen, steps_per_epoch=steps_per_epoch,\n",
    "    epochs=n_epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'songbegin \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = ['songbegin']\n",
    "tokens = [[tokenizer.word_index[i] for i in seed]]\n",
    "s = pad_sequences(tokens, maxlen=sequence_len)\n",
    "for _ in range(30):\n",
    "    X = [s, s]\n",
    "    y_hat = model.predict(X)\n",
    "    i = np.argmax(y_hat[0][-1])\n",
    "    tokens[0].append(i)\n",
    "    s = pad_sequences(tokens, maxlen=sequence_len)\n",
    "' '.join([index_to_word.get(x, '<pad>') for x in tokens[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = ['you', 'are']\n",
    "tokens = [[tokenizer.word_index[i] for i in seed]]\n",
    "print(tokens)\n",
    "s = pad_sequences(tokens, maxlen=sequence_len)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, _ = X\n",
    "[index_to_word.get(i, '<pad>') for i in x1[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [s, s]\n",
    "y_hat = model.predict(X)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[index_to_word.get(i, '<pad>') for i in np.argmax(y_hat[-1], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_hat[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
